<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.webp" color="#222">
  <meta name="google-site-verification" content="Cj9oDgXxdJe6MoA_lEUQ2rmOouwJeTm5uJNqjhOv8Ng">
  <meta name="msvalidate.01" content="E5D0AA8F5E012DFD9C5F3954DF8283B1">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,700,700italic%7CNoto+Serif+SC:300,300italic,400,400italic,700,700italic%7CSource+Code+Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"shenxiaohai.me","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.15.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"default"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":"twikoo","storage":true,"lazyload":false,"nav":null,"activeClass":"twikoo"},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="参照fast.ai第九课的课程和代码，逐步实现： 多标签分类； 构建多分类和多BBox的数据集； 基于ResNet34，构建SSD网络结构；基于anchor box，定义SSD损失函数； 创建更多的anchor来优化模型； 使用Focal Loss；NMS选BBox。">
<meta property="og:type" content="article">
<meta property="og:title" content="在PASCAL VOC数据集上的多目标检测">
<meta property="og:url" content="https://shenxiaohai.me/fastai-9-objctDetctMulti/index.html">
<meta property="og:site_name" content="SHEN&#39;s DevNotes">
<meta property="og:description" content="参照fast.ai第九课的课程和代码，逐步实现： 多标签分类； 构建多分类和多BBox的数据集； 基于ResNet34，构建SSD网络结构；基于anchor box，定义SSD损失函数； 创建更多的anchor来优化模型； 使用Focal Loss；NMS选BBox。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511054/blog/ad0lgyp7alse1nmmc6ww.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511055/blog/xvl3dkearkwldhchwvfv.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511056/blog/sqhte4ytwtg73mrtkoy4.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511059/blog/sht7iauzr5bld954ljte.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511060/blog/b0izkgrkealqwymbyddo.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511060/blog/kpmsygbtdxl5jumrv634.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511061/blog/qtosj4xvsncebveyy4pe.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511062/blog/eu9ycjxdtpkvjjla08ab.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511062/blog/tsh3hfhkcxn8okztpd85.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511063/blog/vsis5zn1svj9bevxalcw.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511066/blog/rq9kwshjc7cffthuqibm.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511066/blog/bcwryesvgselwd9rxw4n.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511067/blog/nvhsfugstdvseeszmr3p.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511068/blog/uv6kogwva6topimp4jky.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511069/blog/xcu7bpdgeziyocangniv.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511072/blog/u6gammhuheheimlrh6eg.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511074/blog/sfs77pk3q1r6np6d8uo0.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511074/blog/nzu2fbaqgrmi38oxwgzo.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511075/blog/rlbuanobuutmhug6gpwb.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511076/blog/ysfwavryof5vyc5y3rr0.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511077/blog/pcazwowwhtiyurhockb5.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511078/blog/esgqtsejxlirskms4eha.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511078/blog/khunfrjqzqqxwsvquj8b.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511079/blog/b6b5uzctq3fk7q03hjsz.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511079/blog/mj26f60dtkuwoc5cntwy.png">
<meta property="article:published_time" content="2018-11-22T09:39:14.000Z">
<meta property="article:modified_time" content="2023-04-02T11:05:03.273Z">
<meta property="article:author" content="xiaohai">
<meta property="article:tag" content="计算机视觉">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="PyTorch">
<meta property="article:tag" content="fast.ai">
<meta property="article:tag" content="SSD">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511054/blog/ad0lgyp7alse1nmmc6ww.png">


<link rel="canonical" href="https://shenxiaohai.me/fastai-9-objctDetctMulti/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://shenxiaohai.me/fastai-9-objctDetctMulti/","path":"fastai-9-objctDetctMulti/","title":"在PASCAL VOC数据集上的多目标检测"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>在PASCAL VOC数据集上的多目标检测 | SHEN's DevNotes</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-YDT7F4NZP6"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"G-YDT7F4NZP6","only_pageview":false}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="SHEN's DevNotes" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">SHEN's DevNotes</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">学习笔记，编程技巧，效率工具</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">131</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">18</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">74</span></a></li><li class="menu-item menu-item-碎碎念-|-memos"><a href="https://memos.shenxiaohai.me/" rel="section" target="_blank"><i class="fa fa-file-pen fa-fw"></i>碎碎念 | Memos</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Fast-ai-Lesson-9-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%EF%BC%88%E5%A4%9A%E7%9B%AE%E6%A0%87%EF%BC%89"><span class="nav-text">Fast.ai Lesson 9: 目标检测（多目标）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%9D%E5%A7%8B%E8%AE%BE%E7%BD%AE%EF%BC%88%E5%90%8C%E4%B8%8A%E7%AF%87%E5%8D%95%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E8%AE%BE%E7%BD%AE%E7%9B%B8%E5%90%8C%EF%BC%89"><span class="nav-text">初始设置（同上篇单目标检测的设置相同）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98"><span class="nav-text">多标签分类问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-text">数据预处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E5%92%8C%E8%AE%AD%E7%BB%83"><span class="nav-text">多分类模型和训练</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="nav-text">目标检测</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE"><span class="nav-text">数据</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9E%84%E5%BB%BA%E5%A4%9A%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">构建多分类数据集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9E%84%E5%BB%BABBox%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">构建BBox的数据集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%B9%E5%A4%9A%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86%E5%92%8CBBox%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BF%9B%E8%A1%8C%E6%8B%BC%E6%8E%A5"><span class="nav-text">对多分类数据集和BBox数据集进行拼接</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8B%E6%96%B0%E6%9E%84%E5%BB%BA%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">查看新构建的数据集</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-text">网络结构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#anchor%E8%AE%BE%E7%BD%AE"><span class="nav-text">anchor设置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E9%AB%98%E7%BA%A7%E7%BD%91%E7%BB%9C%E5%B1%82"><span class="nav-text">自定义高级网络层</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-text">损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E5%88%86%E7%B1%BB%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-text">多分类损失函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#IOU-%E8%AE%A1%E7%AE%97%EF%BC%88%E5%AE%9A%E4%BD%8D%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%89"><span class="nav-text">IOU 计算（定位损失函数）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Loss%E6%B5%8B%E8%AF%95"><span class="nav-text">Loss测试</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="nav-text">训练模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E6%A8%A1%E5%9E%8B"><span class="nav-text">测试模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9B%B4%E6%8E%A5%E9%A2%84%E6%B5%8B"><span class="nav-text">直接预测</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%87%E4%B8%80%E9%81%8D%E6%B5%81%E7%A8%8B%EF%BC%8C%E5%8A%A0%E5%BC%BA%E7%90%86%E8%A7%A3"><span class="nav-text">过一遍流程，加强理解</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%9B%E4%B8%80%E6%AD%A5%E7%9A%84%E6%94%B9%E8%BF%9B%EF%BC%9A%E6%9B%B4%E5%A4%9A%E7%9A%84anchor-box"><span class="nav-text">进一步的改进：更多的anchor box</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E6%9B%B4%E5%A4%9A%E7%9A%84anchor"><span class="nav-text">创建更多的anchor</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E6%A8%A1%E5%9E%8B"><span class="nav-text">创建模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E5%92%8C%E6%B5%8B%E8%AF%95"><span class="nav-text">训练和测试</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Focal-Loss"><span class="nav-text">Focal Loss</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9A%E4%B9%89Focal-Loss"><span class="nav-text">定义Focal Loss</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E5%92%8C%E6%B5%8B%E8%AF%95-1"><span class="nav-text">训练和测试</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9D%9E%E6%9E%81%E5%A4%A7%E6%8A%91%E5%88%B6%EF%BC%88NMS%EF%BC%89"><span class="nav-text">非极大抑制（NMS）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#End"><span class="nav-text">End</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">xiaohai</p>
  <div class="site-description" itemprop="description">我在这个技术博客中分享学习笔记，提供实用技巧和工具资源。</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">74</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">131</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/veraposeidon" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;veraposeidon" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/HiYoake" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;HiYoake" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/big/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://shenxiaohai.me/fastai-9-objctDetctMulti/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="xiaohai">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SHEN's DevNotes">
      <meta itemprop="description" content="我在这个技术博客中分享学习笔记，提供实用技巧和工具资源。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="在PASCAL VOC数据集上的多目标检测 | SHEN's DevNotes">
      <meta itemprop="description" content="参照fast.ai第九课的课程和代码，逐步实现：</br> 多标签分类； </br>构建多分类和多BBox的数据集；</br> 基于ResNet34，构建SSD网络结构；</br>基于anchor box，定义SSD损失函数；</br> 创建更多的anchor来优化模型；</br> 使用Focal Loss；</br>NMS选BBox。">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          在PASCAL VOC数据集上的多目标检测
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2018-11-22 09:39:14" itemprop="dateCreated datePublished" datetime="2018-11-22T09:39:14Z">2018-11-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-02 11:05:03" itemprop="dateModified" datetime="2023-04-02T11:05:03Z">2023-04-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" itemprop="url" rel="index"><span itemprop="name">计算机视觉</span></a>
        </span>
    </span>

  
</div>

            <div class="post-description">参照fast.ai第九课的课程和代码，逐步实现：</br> 多标签分类； </br>构建多分类和多BBox的数据集；</br> 基于ResNet34，构建SSD网络结构；</br>基于anchor box，定义SSD损失函数；</br> 创建更多的anchor来优化模型；</br> 使用Focal Loss；</br>NMS选BBox。</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="Fast-ai-Lesson-9-目标检测（多目标）"><a href="#Fast-ai-Lesson-9-目标检测（多目标）" class="headerlink" title="Fast.ai Lesson 9: 目标检测（多目标）"></a>Fast.ai Lesson 9: 目标检测（多目标）</h1><p>fast.ai 0.7版本</p>
<p>Pytorch 0.3版本</p>
<p>参考：</p>
<p><a target="_blank" rel="noopener" href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-9-5f0cf9e4bb5b">【Deep Learning 2: Part 2 Lesson 9】</a></p>
<p><a target="_blank" rel="noopener" href="https://forums.fast.ai/t/deeplearning-lec9-notes/14113?u=cedric">【DeepLearning-Lec9-Notes】</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># jupyter 初始化</span></span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format=<span class="string">&quot;retina&quot;</span></span><br><span class="line">%config InlineBackend.rc = &#123;<span class="string">&quot;figure.figsize&quot;</span>: (<span class="number">7.5</span>,<span class="number">4.5</span>)&#125;</span><br><span class="line"></span><br><span class="line">%reload_ext autoreload</span><br><span class="line">%autoreload <span class="number">2</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import packages</span></span><br><span class="line"><span class="keyword">from</span> fastai.conv_learner <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> fastai.dataset <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json, pdb</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> ImageDraw, ImageFont</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> patches, patheffects</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置运行GPU</span></span><br><span class="line">torch.cuda.set_device(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>关于<code>torch.backends.cudnn.benchmark=True</code>的使用</p>
<p>参考链接：<a target="_blank" rel="noopener" href="https://www.pytorchtutorial.com/when-should-we-set-cudnn-benchmark-to-true/">什么情况下应该设置 cudnn.benchmark &#x3D; True？</a></p>
<p>大部分情况下，设置这个 flag 可以让内置的 cuDNN 的 auto-tuner 自动寻找最适合当前配置的高效算法，来达到优化运行效率的问题。</p>
<p>一般来讲，应该遵循以下准则：</p>
<ul>
<li>如果网络的输入数据维度或类型上变化不大，设置  torch.backends.cudnn.benchmark &#x3D; true  可以增加运行效率；</li>
<li>如果网络的输入数据在每次 iteration 都变化的话，会导致 cnDNN 每次都会去寻找一遍最优配置，这样反而会降低运行效率。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 优化运行效率</span></span><br><span class="line">torch.backends.cudnn.benchmark=<span class="literal">True</span></span><br></pre></td></tr></table></figure>

<h2 id="初始设置（同上篇单目标检测的设置相同）"><a href="#初始设置（同上篇单目标检测的设置相同）" class="headerlink" title="初始设置（同上篇单目标检测的设置相同）"></a>初始设置（同上篇单目标检测的设置相同）</h2><ul>
<li>路径</li>
<li>构建图像-路径-分类-BBox的关系字典</li>
<li>可视化功能</li>
<li>BBox表征方式转换函数</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 路径</span></span><br><span class="line">PATH = Path(<span class="string">&#x27;data/pascal2007&#x27;</span>)</span><br><span class="line"></span><br><span class="line">trin_json = json.load((PATH / <span class="string">&#x27;pascal_train2007.json&#x27;</span>).<span class="built_in">open</span>())</span><br><span class="line"></span><br><span class="line">IMAGES,ANNOTATIONS,CATEGORIES = [<span class="string">&#x27;images&#x27;</span>, <span class="string">&#x27;annotations&#x27;</span>, <span class="string">&#x27;categories&#x27;</span>]</span><br><span class="line"></span><br><span class="line">FILE_NAME,ID,IMG_ID,CAT_ID,BBOX = [<span class="string">&#x27;file_name&#x27;</span>,<span class="string">&#x27;id&#x27;</span>,<span class="string">&#x27;image_id&#x27;</span>,<span class="string">&#x27;category_id&#x27;</span>,<span class="string">&#x27;bbox&#x27;</span>]</span><br><span class="line"></span><br><span class="line">JPEGS = <span class="string">&#x27;VOCdevkit/VOC2007/JPEGImages&#x27;</span></span><br><span class="line">IMG_PATH = PATH / JPEGS</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建关系字典</span></span><br><span class="line"><span class="comment"># ID-&gt;类别</span></span><br><span class="line">catgoris = &#123;o[ID]:o[<span class="string">&#x27;name&#x27;</span>] <span class="keyword">for</span> o <span class="keyword">in</span> trin_json[CATEGORIES]&#125;</span><br><span class="line"><span class="comment"># ID-&gt;路径</span></span><br><span class="line">trinFnams = &#123;o[ID]:o[FILE_NAME] <span class="keyword">for</span> o <span class="keyword">in</span> trin_json[IMAGES]&#125;</span><br><span class="line"><span class="comment"># ID</span></span><br><span class="line">trinIDs = [o[ID] <span class="keyword">for</span> o <span class="keyword">in</span> trin_json[IMAGES]]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 转换BBOX（x,y,w,h）-&gt; （y1,x1,y2,x2）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hw_bb</span>(<span class="params">bb</span>):</span><br><span class="line">    <span class="keyword">return</span> np.array([bb[<span class="number">1</span>],bb[<span class="number">0</span>],bb[<span class="number">3</span>]+bb[<span class="number">1</span>]-<span class="number">1</span>, bb[<span class="number">2</span>]+bb[<span class="number">0</span>]-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换BBOX（y1,x1,y2,x2）-&gt; （x,y,w,h）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bb_hw</span>(<span class="params">bb</span>):</span><br><span class="line">    <span class="keyword">return</span> np.array([bb[<span class="number">1</span>],bb[<span class="number">0</span>],bb[<span class="number">3</span>]-bb[<span class="number">1</span>]+<span class="number">1</span>,bb[<span class="number">2</span>]-bb[<span class="number">0</span>]+<span class="number">1</span>])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标注信息字典：ID-&gt;anno</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_trn_anno</span>():</span><br><span class="line">    trin_anno = collections.defaultdict(<span class="keyword">lambda</span>:[])</span><br><span class="line">    <span class="keyword">for</span> o <span class="keyword">in</span> trin_json[ANNOTATIONS]:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> o[<span class="string">&#x27;ignore&#x27;</span>]:</span><br><span class="line">            bb = o[BBOX]</span><br><span class="line">            bb = np.array(hw_bb(bb)) <span class="comment"># 存储左上右下两点形式</span></span><br><span class="line">            trin_anno[o[IMG_ID]].append((bb,o[CAT_ID]))</span><br><span class="line">    <span class="keyword">return</span> trin_anno</span><br><span class="line">            </span><br><span class="line">trinAnnos = get_trn_anno()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义可视化函数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># matplotlib 对象</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_img</span>(<span class="params">im, figsize=<span class="literal">None</span>, ax=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> ax: fig,ax = plt.subplots(figsize=figsize)</span><br><span class="line">    ax.imshow(im)</span><br><span class="line">    ax.set_xticks(np.linspace(<span class="number">0</span>, <span class="number">224</span>, <span class="number">8</span>))</span><br><span class="line">    ax.set_yticks(np.linspace(<span class="number">0</span>, <span class="number">224</span>, <span class="number">8</span>))</span><br><span class="line">    ax.grid()</span><br><span class="line">    ax.set_yticklabels([])</span><br><span class="line">    ax.set_xticklabels([])</span><br><span class="line">    <span class="keyword">return</span> ax</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图像包边</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_outline</span>(<span class="params">o, lw</span>):</span><br><span class="line">    o.set_path_effects([patheffects.Stroke(</span><br><span class="line">        linewidth=lw, foreground=<span class="string">&#x27;black&#x27;</span>), patheffects.Normal()])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制BBOX    </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_rect</span>(<span class="params">ax, b, color=<span class="string">&#x27;white&#x27;</span></span>):</span><br><span class="line">    patch = ax.add_patch(patches.Rectangle(b[:<span class="number">2</span>], *b[-<span class="number">2</span>:], fill=<span class="literal">False</span>, edgecolor=color, lw=<span class="number">2</span>))</span><br><span class="line">    draw_outline(patch, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制文本</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_text</span>(<span class="params">ax, xy, txt, sz=<span class="number">14</span>, color=<span class="string">&#x27;white&#x27;</span></span>):</span><br><span class="line">    text = ax.text(*xy, txt,</span><br><span class="line">        verticalalignment=<span class="string">&#x27;top&#x27;</span>, color=color, fontsize=sz, weight=<span class="string">&#x27;bold&#x27;</span>)</span><br><span class="line">    draw_outline(text, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制图像和标注</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_im</span>(<span class="params">im, ann</span>):</span><br><span class="line">    ax = show_img(im, figsize=(<span class="number">16</span>,<span class="number">8</span>))</span><br><span class="line">    <span class="keyword">for</span> b,c <span class="keyword">in</span> ann:</span><br><span class="line">        b = bb_hw(b)</span><br><span class="line">        draw_rect(ax, b)</span><br><span class="line">        draw_text(ax, b[:<span class="number">2</span>], catgoris[c], sz=<span class="number">16</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据ID绘制图像</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_idx</span>(<span class="params">i</span>):</span><br><span class="line">    im_a = trinAnnos[i]</span><br><span class="line">    im = open_image(IMG_PATH/trinFnams[i])</span><br><span class="line">    draw_im(im, im_a)</span><br></pre></td></tr></table></figure>

<h2 id="多标签分类问题"><a href="#多标签分类问题" class="headerlink" title="多标签分类问题"></a>多标签分类问题</h2><p>如同卫星图像分类一样，一幅图分配几个分类标签</p>
<h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MC_CSV = PATH/<span class="string">&#x27;tmp/mc.csv&#x27;</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trinAnnos[<span class="number">12</span>]</span><br></pre></td></tr></table></figure>




<pre><code>[(array([ 96, 155, 269, 350]), 7)]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 统计每幅图中的分类，set的作用是方式重复</span></span><br><span class="line">multiClass = [<span class="built_in">set</span>(catgoris[p[<span class="number">1</span>]] <span class="keyword">for</span> p <span class="keyword">in</span> trinAnnos[o]) <span class="keyword">for</span> o <span class="keyword">in</span> trinIDs]</span><br><span class="line"><span class="comment"># 统计每幅图中的分类，用空格分开</span></span><br><span class="line">multiClasses = [<span class="string">&#x27; &#x27;</span>.join(<span class="built_in">str</span>(p) <span class="keyword">for</span> p <span class="keyword">in</span> o) <span class="keyword">for</span> o <span class="keyword">in</span> multiClass]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 写入CSV文件</span></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;fn&#x27;</span>: [trinFnams[o] <span class="keyword">for</span> o <span class="keyword">in</span> trinIDs], <span class="string">&#x27;clas&#x27;</span>: multiClasses&#125;, columns=[<span class="string">&#x27;fn&#x27;</span>,<span class="string">&#x27;clas&#x27;</span>])</span><br><span class="line">df.to_csv(MC_CSV, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<h3 id="多分类模型和训练"><a href="#多分类模型和训练" class="headerlink" title="多分类模型和训练"></a>多分类模型和训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">f_model=resnet34</span><br><span class="line">sz=<span class="number">224</span></span><br><span class="line">bs=<span class="number">64</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tfms = tfms_from_model(f_model=f_model, sz=sz,crop_type=CropType.NO)</span><br><span class="line">md = ImageClassifierData.from_csv(path=PATH, folder=JPEGS, csv_fname=MC_CSV, tfms=tfms, bs=bs)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置学习器及优化函数</span></span><br><span class="line">learn = ConvLearner.pretrained(f_model,data=md)</span><br><span class="line">learn.opt_fn = optim.Adam</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 找最优学习率</span></span><br><span class="line">lrf=learn.lr_find(<span class="number">1e-5</span>,<span class="number">100</span>)</span><br></pre></td></tr></table></figure>


<pre><code>epoch      trn_loss   val_loss   &lt;lambda&gt;                  
    0      1.33405    13.517095  0.5108    
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learn.sched.plot(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511054/blog/ad0lgyp7alse1nmmc6ww.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lr = <span class="number">2e-2</span></span><br></pre></td></tr></table></figure>

<p>关于use_clr的用法：第一个参数是关于精度的，从lr的1&#x2F;32开始，第二个参数是上升与下降比例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learn.fit(lr, <span class="number">1</span>, cycle_len=<span class="number">3</span>, use_clr=(<span class="number">32</span>,<span class="number">5</span>))</span><br></pre></td></tr></table></figure>


<pre><code>epoch      trn_loss   val_loss   &lt;lambda&gt;                  
    0      0.322894   0.165013   0.9484    
    1      0.173385   0.079073   0.9731                    
    2      0.116328   0.074583   0.9748                    


[array([0.07458]), 0.9747999939918518]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lrs = np.array([lr/<span class="number">100</span>, lr/<span class="number">10</span>, lr])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learn.freeze_to(-<span class="number">2</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">learn.lr_find(lrs/<span class="number">1000</span>)</span><br><span class="line">learn.sched.plot(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>


<pre><code> 84%|████████▍ | 27/32 [00:05&lt;00:00,  7.20it/s, loss=0.243] 
                                                           
</code></pre>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511055/blog/xvl3dkearkwldhchwvfv.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learn.fit(lrs/<span class="number">10</span>, <span class="number">1</span>, cycle_len=<span class="number">5</span>, use_clr=(<span class="number">32</span>,<span class="number">5</span>))</span><br></pre></td></tr></table></figure>



<pre><code>epoch      trn_loss   val_loss   &lt;lambda&gt;                   
    0      0.075259   0.078922   0.9734    
    1      0.054866   0.080068   0.9744                     
    2      0.03906    0.079555   0.9764                     
    3      0.028415   0.073445   0.9767                     
    4      0.02       0.075055   0.9771                     


[array([0.07505]), 0.9770999913215637]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存/加载模型</span></span><br><span class="line">learn.save(<span class="string">&#x27;mclas&#x27;</span>)</span><br><span class="line">learn.load(<span class="string">&#x27;mclas&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y = learn.predict() <span class="comment"># 默认用Validation集进行预测</span></span><br><span class="line">x,_ = <span class="built_in">next</span>(<span class="built_in">iter</span>(md.val_dl))</span><br><span class="line">x = to_np(x)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看多分类效果</span></span><br><span class="line">fig, axes = plt.subplots(<span class="number">3</span>, <span class="number">4</span>, figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line"><span class="keyword">for</span> i,ax <span class="keyword">in</span> <span class="built_in">enumerate</span>(axes.flat):</span><br><span class="line">    ima=md.val_ds.denorm(x)[i]</span><br><span class="line">    ya = np.nonzero(y[i]&gt;<span class="number">0.4</span>)[<span class="number">0</span>]</span><br><span class="line">    b = <span class="string">&#x27;\n&#x27;</span>.join(md.classes[o] <span class="keyword">for</span> o <span class="keyword">in</span> ya)</span><br><span class="line">    ax = show_img(ima, ax=ax)</span><br><span class="line">    draw_text(ax, (<span class="number">0</span>,<span class="number">0</span>), b)</span><br><span class="line">plt.tight_layout()</span><br></pre></td></tr></table></figure>

<pre><code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
</code></pre>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511056/blog/sqhte4ytwtg73mrtkoy4.png" alt="png"></p>
<p>多分类还是比较简单直白的。</p>
<h2 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h2><p>按照Howard教授讲的,实现一个粗糙版本的SSD，继而进行改进。</p>
<p>训练网络的三要素：</p>
<ol>
<li>数据</li>
<li>网络结构</li>
<li>Loss函数</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 超参数</span></span><br><span class="line">f_model=resnet34</span><br><span class="line">sz=<span class="number">224</span></span><br><span class="line">bs=<span class="number">64</span></span><br></pre></td></tr></table></figure>

<h3 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h3><h4 id="构建多分类数据集"><a href="#构建多分类数据集" class="headerlink" title="构建多分类数据集"></a>构建多分类数据集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">multiClass = [[catgoris[p[<span class="number">1</span>]] <span class="keyword">for</span> p <span class="keyword">in</span> trinAnnos[o]] <span class="keyword">for</span> o <span class="keyword">in</span> trinIDs] <span class="comment"># 这次没用到set,是因为要用到每个bbox的对应的标签</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建索引：ID-&gt;分类名</span></span><br><span class="line">Id2Catgris = <span class="built_in">list</span>(catgoris.values())</span><br><span class="line"><span class="comment"># 构建索引：分类名-&gt;ID</span></span><br><span class="line">Catgris2Id = &#123;v:k <span class="keyword">for</span> k,v <span class="keyword">in</span> <span class="built_in">enumerate</span>(Id2Catgris)&#125; </span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建索引:图像ID-&gt;各图像中的分类ID</span></span><br><span class="line">multiClasses = np.array([np.array([Catgris2Id[p] <span class="keyword">for</span> p <span class="keyword">in</span> o]) <span class="keyword">for</span> o <span class="keyword">in</span> multiClass])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可以看到，multiClasses里包含就是每幅图的分类ID（可重复）</span></span><br><span class="line">multiClasses</span><br></pre></td></tr></table></figure>




<pre><code>array([array([6]), array([14, 12]), array([ 1,  1, 14, 14, 14]), ..., array([17,  8, 14, 14, 14]),
       array([6]), array([11])], dtype=object)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 交叉验证分割</span></span><br><span class="line">val_idxs = get_cv_idxs(<span class="built_in">len</span>(trinFnams))</span><br><span class="line">((val_mcs,trn_mcs),) = split_by_idx(val_idxs, multiClasses)</span><br></pre></td></tr></table></figure>

<h4 id="构建BBox的数据集"><a href="#构建BBox的数据集" class="headerlink" title="构建BBox的数据集"></a>构建BBox的数据集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MBB_CSV = PATH/<span class="string">&#x27;tmp/mbb.csv&#x27;</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取BBOX的数据</span></span><br><span class="line">multiBBox = [np.concatenate([p[<span class="number">0</span>] <span class="keyword">for</span> p <span class="keyword">in</span> trinAnnos[o]]) <span class="keyword">for</span> o <span class="keyword">in</span> trinIDs]</span><br><span class="line">multiBBoxes = [<span class="string">&#x27; &#x27;</span>.join(<span class="built_in">str</span>(p) <span class="keyword">for</span> p <span class="keyword">in</span> o) <span class="keyword">for</span> o <span class="keyword">in</span> multiBBox] <span class="comment"># 转换成空格间隔，用于存入CSV</span></span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;fn&#x27;</span>:[trinFnams[o] <span class="keyword">for</span> o <span class="keyword">in</span> trinIDs], <span class="string">&#x27;bbox&#x27;</span>:multiBBoxes&#125;, columns=[<span class="string">&#x27;fn&#x27;</span>,<span class="string">&#x27;bbox&#x27;</span>])</span><br><span class="line">df.to_csv(MBB_CSV, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></table></figure>


<table>
<thead>
<tr>
<th></th>
<th>fn</th>
<th>bbox</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>000012.jpg</td>
<td>96 155 269 350</td>
</tr>
<tr>
<td>1</td>
<td>000017.jpg</td>
<td>61 184 198 278 77 89 335 402</td>
</tr>
<tr>
<td>2</td>
<td>000023.jpg</td>
<td>229 8 499 244 219 229 499 333 0 1 368 116 1 2 …</td>
</tr>
<tr>
<td>3</td>
<td>000026.jpg</td>
<td>124 89 211 336</td>
</tr>
<tr>
<td>4</td>
<td>000032.jpg</td>
<td>77 103 182 374 87 132 122 196 179 194 228 212 …</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于BBOX的数据增强，注意COORD格式</span></span><br><span class="line">aug_tfms = [RandomRotate(<span class="number">3</span>, p=<span class="number">0.5</span>, tfm_y=TfmType.COORD),</span><br><span class="line">            RandomLighting(<span class="number">0.05</span>, <span class="number">0.05</span>, tfm_y=TfmType.COORD),</span><br><span class="line">            RandomFlip(tfm_y=TfmType.COORD)]</span><br><span class="line">tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.COORD, aug_tfms=aug_tfms)</span><br><span class="line">md = ImageClassifierData.from_csv(PATH, JPEGS, MBB_CSV, tfms=tfms, bs=bs, continuous=<span class="literal">True</span>, num_workers=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<h4 id="对多分类数据集和BBox数据集进行拼接"><a href="#对多分类数据集和BBox数据集进行拼接" class="headerlink" title="对多分类数据集和BBox数据集进行拼接"></a>对多分类数据集和BBox数据集进行拼接</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造一个拼接的数据集：multiBBox + multiClasses</span></span><br><span class="line"><span class="comment"># 注意：都是通过ID索引的</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConcatLblDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ds, y2</span>):</span><br><span class="line">        self.ds,self.y2 = ds,y2</span><br><span class="line">        self.sz = ds.sz</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>): <span class="keyword">return</span> <span class="built_in">len</span>(self.ds)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, i</span>):</span><br><span class="line">        x,y = self.ds[i]</span><br><span class="line">        <span class="keyword">return</span> (x, (y,self.y2[i]))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拼接并替换</span></span><br><span class="line">trn_ds2 = ConcatLblDataset(md.trn_ds, trn_mcs)</span><br><span class="line">val_ds2 = ConcatLblDataset(md.val_ds, val_mcs)</span><br><span class="line">md.trn_dl.dataset = trn_ds2</span><br><span class="line">md.val_dl.dataset = val_ds2</span><br></pre></td></tr></table></figure>

<h4 id="查看新构建的数据集"><a href="#查看新构建的数据集" class="headerlink" title="查看新构建的数据集"></a>查看新构建的数据集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.cm <span class="keyword">as</span> cmx</span><br><span class="line"><span class="keyword">import</span> matplotlib.colors <span class="keyword">as</span> mcolors</span><br><span class="line"><span class="keyword">from</span> cycler <span class="keyword">import</span> cycler</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_cmap</span>(<span class="params">N</span>):</span><br><span class="line">    color_norm  = mcolors.Normalize(vmin=<span class="number">0</span>, vmax=N-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> cmx.ScalarMappable(norm=color_norm, cmap=<span class="string">&#x27;Set3&#x27;</span>).to_rgba</span><br><span class="line"></span><br><span class="line">num_colr = <span class="number">12</span></span><br><span class="line">cmap = get_cmap(num_colr)</span><br><span class="line">colr_list = [cmap(<span class="built_in">float</span>(x)) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(num_colr)]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">show_ground_truth</span>(<span class="params">ax, im, bbox, clas=<span class="literal">None</span>, prs=<span class="literal">None</span>, thresh=<span class="number">0.3</span></span>):</span><br><span class="line">    bb = [bb_hw(o) <span class="keyword">for</span> o <span class="keyword">in</span> bbox.reshape(-<span class="number">1</span>,<span class="number">4</span>)]</span><br><span class="line">    <span class="keyword">if</span> prs <span class="keyword">is</span> <span class="literal">None</span>:  prs  = [<span class="literal">None</span>]*<span class="built_in">len</span>(bb)</span><br><span class="line">    <span class="keyword">if</span> clas <span class="keyword">is</span> <span class="literal">None</span>: clas = [<span class="literal">None</span>]*<span class="built_in">len</span>(bb)</span><br><span class="line">    ax = show_img(im, ax=ax)</span><br><span class="line">    <span class="keyword">for</span> i,(b,c,pr) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(bb, clas, prs)):</span><br><span class="line">        <span class="comment"># 注意：原jupyter此处条件之一是b[2]&gt;0，意思是宽大于0即可，调试发现并不可，需大于1</span></span><br><span class="line">        <span class="keyword">if</span>((b[<span class="number">2</span>]&gt;<span class="number">1</span>) <span class="keyword">and</span> (pr <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> pr &gt; thresh)):</span><br><span class="line">            draw_rect(ax, b, color=colr_list[i%num_colr])</span><br><span class="line">            txt = <span class="string">f&#x27;<span class="subst">&#123;i&#125;</span>: &#x27;</span></span><br><span class="line">            <span class="keyword">if</span> c <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: txt += (<span class="string">&#x27;bg&#x27;</span> <span class="keyword">if</span> c==<span class="built_in">len</span>(Id2Catgris) <span class="keyword">else</span> Id2Catgris[c])</span><br><span class="line">            <span class="keyword">if</span> pr <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: txt += <span class="string">f&#x27; <span class="subst">&#123;pr:<span class="number">.2</span>f&#125;</span>&#x27;</span></span><br><span class="line">            draw_text(ax, b[:<span class="number">2</span>], txt, color=colr_list[i%num_colr])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取一个batch</span></span><br><span class="line">x,y = to_np(<span class="built_in">next</span>(<span class="built_in">iter</span>(md.val_dl)))</span><br><span class="line">x = md.val_ds.ds.denorm(x)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">fig, axes = plt.subplots(<span class="number">3</span>,<span class="number">4</span>, figsize=(<span class="number">16</span>,<span class="number">12</span>))</span><br><span class="line"><span class="keyword">for</span> i,ax <span class="keyword">in</span> <span class="built_in">enumerate</span>(axes.flat):</span><br><span class="line">    show_ground_truth(ax, x[i], y[<span class="number">0</span>][i], y[<span class="number">1</span>][i]) <span class="comment"># x[i] 图像， y[0][i] BBoxs，y[1][i]classes</span></span><br><span class="line">plt.tight_layout()</span><br></pre></td></tr></table></figure>

<pre><code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
</code></pre>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511059/blog/sht7iauzr5bld954ljte.png" alt="png"></p>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>先构建简单的模型，后继续改进。先用4x4 anchor。</p>
<p>这里用的是SSD的方式：</p>
<ul>
<li>SSD的方式是在原有ResNet主干后增加一个stride为2的卷积层，得到4x4的tensor，对每个Tensor做（4+C）的目标检测，共4<em>4</em>（4+C）；</li>
<li>YOLO的方式是直接构建16*(4+C)的Linear层。</li>
</ul>
<h4 id="anchor设置"><a href="#anchor设置" class="headerlink" title="anchor设置"></a>anchor设置</h4><p>参数介绍：</p>
<ul>
<li>anc_grid &#x3D; how big of a square grid to make (subdivision)</li>
<li>anc_offset &#x3D; center offsets</li>
<li>anc_x &#x3D; x coordinates for centers</li>
<li>anc_y &#x3D; y coordinates for centers</li>
<li>anc_ctrs - the actual coordinates for the grid centers</li>
<li>anc_sizes - size of the quadrants</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># anchor 超参数</span></span><br><span class="line">anc_grid = <span class="number">4</span> <span class="comment"># 将图像细分的个数</span></span><br><span class="line">k = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建anchor</span></span><br><span class="line">anc_offset = <span class="number">1</span>/(anc_grid*<span class="number">2</span>) <span class="comment"># anchors中心偏移（小数形式）</span></span><br><span class="line">anc_x = np.repeat(np.linspace(anc_offset, <span class="number">1</span> - anc_offset, anc_grid), anc_grid) <span class="comment"># 横轴 anchor中心分布（小数形式）</span></span><br><span class="line">anc_y = np.tile(np.linspace(anc_offset,<span class="number">1</span>-anc_offset,anc_grid),anc_grid) <span class="comment"># 纵轴 anchor中心分布（小数形式）</span></span><br><span class="line"></span><br><span class="line">anc_ctrs = np.tile(np.stack([anc_x,anc_y], axis=<span class="number">1</span>), (k,<span class="number">1</span>)) <span class="comment"># anchor中心实际坐标</span></span><br><span class="line">anc_sizes = np.array([[<span class="number">1</span>/anc_grid,<span class="number">1</span>/anc_grid] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(anc_grid*anc_grid)]) <span class="comment"># 每个anchor的size（实际大小）</span></span><br><span class="line">anchors = V(np.concatenate([anc_ctrs, anc_sizes], axis=<span class="number">1</span>), requires_grad=<span class="literal">False</span>).<span class="built_in">float</span>() <span class="comment"># 构建anchor向量，放入GPU</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grid_sizes = V(np.array([<span class="number">1</span>/anc_grid]), requires_grad=<span class="literal">False</span>).unsqueeze(<span class="number">1</span>) <span class="comment"># 每个anchor的大小比例,放入GPU</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制anchor分布</span></span><br><span class="line">plt.grid(<span class="literal">False</span>)</span><br><span class="line">plt.scatter(anc_x, anc_y)</span><br><span class="line">plt.xlim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">1</span>);</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511060/blog/b0izkgrkealqwymbyddo.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出anchor 中心和长宽（坐标）</span></span><br><span class="line"><span class="built_in">print</span>(anchors)</span><br></pre></td></tr></table></figure>

<pre><code>Variable containing:
 0.1250  0.1250  0.2500  0.2500
 0.1250  0.3750  0.2500  0.2500
 0.1250  0.6250  0.2500  0.2500
 0.1250  0.8750  0.2500  0.2500
 0.3750  0.1250  0.2500  0.2500
 0.3750  0.3750  0.2500  0.2500
 0.3750  0.6250  0.2500  0.2500
 0.3750  0.8750  0.2500  0.2500
 0.6250  0.1250  0.2500  0.2500
 0.6250  0.3750  0.2500  0.2500
 0.6250  0.6250  0.2500  0.2500
 0.6250  0.8750  0.2500  0.2500
 0.8750  0.1250  0.2500  0.2500
 0.8750  0.3750  0.2500  0.2500
 0.8750  0.6250  0.2500  0.2500
 0.8750  0.8750  0.2500  0.2500
[torch.cuda.FloatTensor of size 16x4 (GPU 1)]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个anchor的 hw-》左上右下 函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hw2corners</span>(<span class="params">ctr, hw</span>):</span><br><span class="line">    <span class="keyword">return</span> torch.cat([ctr-hw/<span class="number">2</span>,ctr+hw/<span class="number">2</span>],dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># anchor分布表示：中心宽高-》左上角右下角</span></span><br><span class="line">anchor_cnr = hw2corners(anchors[:,:<span class="number">2</span>],anchors[:,<span class="number">2</span>:])</span><br><span class="line">anchor_cnr</span><br></pre></td></tr></table></figure>




<pre><code>Variable containing:
 0.0000  0.0000  0.2500  0.2500
 0.0000  0.2500  0.2500  0.5000
 0.0000  0.5000  0.2500  0.7500
 0.0000  0.7500  0.2500  1.0000
 0.2500  0.0000  0.5000  0.2500
 0.2500  0.2500  0.5000  0.5000
 0.2500  0.5000  0.5000  0.7500
 0.2500  0.7500  0.5000  1.0000
 0.5000  0.0000  0.7500  0.2500
 0.5000  0.2500  0.7500  0.5000
 0.5000  0.5000  0.7500  0.7500
 0.5000  0.7500  0.7500  1.0000
 0.7500  0.0000  1.0000  0.2500
 0.7500  0.2500  1.0000  0.5000
 0.7500  0.5000  1.0000  0.7500
 0.7500  0.7500  1.0000  1.0000
[torch.cuda.FloatTensor of size 16x4 (GPU 1)]
</code></pre>
<h4 id="自定义高级网络层"><a href="#自定义高级网络层" class="headerlink" title="自定义高级网络层"></a>自定义高级网络层</h4><p>以ResNet34为主干，追加更多的卷积层。现在是一层卷积层，用于4x4grid。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">n_clas = <span class="built_in">len</span>(Id2Catgris)+<span class="number">1</span> <span class="comment"># 分类数目</span></span><br><span class="line">n_act = k*(<span class="number">4</span>+n_clas) <span class="comment"># activation个数，暂时不去管k</span></span><br></pre></td></tr></table></figure>

<p>关于flatten的方式 (pytorch中contiguous())[<a target="_blank" rel="noopener" href="https://blog.csdn.net/appleml/article/details/80143212]%EF%BC%9A">https://blog.csdn.net/appleml/article/details/80143212]：</a></p>
<p>view只能用在contiguous的variable上。如果在view之前用了transpose, permute等，需要用contiguous()来返回一个contiguous copy。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一个标准卷积层:使用这种方式来减少错误</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">StdConv</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, nin, nout, stride=<span class="number">2</span>, drop=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv = nn.Conv2d(nin, nout, <span class="number">3</span>, stride=stride, padding=<span class="number">1</span>)</span><br><span class="line">        self.bn = nn.BatchNorm2d(nout)</span><br><span class="line">        self.drop = nn.Dropout(drop)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>): <span class="keyword">return</span> self.drop(self.bn(F.relu(self.conv(x))))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">flatten_conv</span>(<span class="params">x,k</span>):</span><br><span class="line">    bs,nf,gx,gy = x.size()</span><br><span class="line">    x = x.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).contiguous() <span class="comment"># 重排</span></span><br><span class="line">    <span class="keyword">return</span> x.view(bs,-<span class="number">1</span>,nf//k)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个输出卷积层</span></span><br><span class="line"><span class="comment"># oconv1用于分类，oconv2用于定位。</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OutConv</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, k, nin, bias</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.k = k</span><br><span class="line">        self.oconv1 = nn.Conv2d(nin, (<span class="built_in">len</span>(Id2Catgris)+<span class="number">1</span>)*k, <span class="number">3</span>, padding=<span class="number">1</span>) <span class="comment"># +1是用于background</span></span><br><span class="line">        self.oconv2 = nn.Conv2d(nin, <span class="number">4</span>*k, <span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.oconv1.bias.data.zero_().add_(bias)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 注意输出的逻辑，写成flatten形式，便于设计实现loss函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> [flatten_conv(self.oconv1(x), self.k),</span><br><span class="line">                flatten_conv(self.oconv2(x), self.k)]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个SSD_Head</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SSD_Head</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, k, bias</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.drop = nn.Dropout(<span class="number">0.25</span>)</span><br><span class="line">        self.sconv0 = StdConv(<span class="number">512</span>,<span class="number">256</span>, stride=<span class="number">1</span>) <span class="comment"># stride为1的卷积并不改变维度大小</span></span><br><span class="line"><span class="comment">#         self.sconv1 = StdConv(256,256)</span></span><br><span class="line">        self.sconv2 = StdConv(<span class="number">256</span>,<span class="number">256</span>) <span class="comment"># 进行标准的卷积层，返回维度大小为4x4,对应图像4个anchor的感受野</span></span><br><span class="line">        self.out = OutConv(k, <span class="number">256</span>, bias) <span class="comment"># 进行输出层处理，注意返回维度，是两个</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.drop(F.relu(x))</span><br><span class="line">        x = self.sconv0(x)</span><br><span class="line"><span class="comment">#         x = self.sconv1(x)</span></span><br><span class="line">        x = self.sconv2(x)</span><br><span class="line">        <span class="keyword">return</span> self.out(x)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新模型</span></span><br><span class="line">head_reg4 = SSD_Head(k, -<span class="number">3.</span>)</span><br><span class="line">models = ConvnetBuilder(f_model, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, custom_head=head_reg4)</span><br><span class="line">learn = ConvLearner(md, models)</span><br><span class="line">learn.opt_fn = optim.Adam</span><br></pre></td></tr></table></figure>

<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>损失函数需要先对图像中的目标对应到最后卷积层的其中一个grid中，就可以说是“这个grid是对这一个目标对标的”；</p>
<p>然后进一步地，去衡量坐标的接近程度和分类概率的接近程度。</p>
<p>损失函数：SSD_Loss的计算步骤：</p>
<ol>
<li>去除zeroPadding</li>
<li>将预测得到的activations转换至BBox（anchor 空间）</li>
<li>计算IOU</li>
<li>将Ground Truth的BBox映射到Anchor 空间</li>
<li>检查是否存在覆盖区域大于0.4的（Ground Truth BBox与4x4的anchors）</li>
<li>寻找匹配的anchor和分类下标</li>
<li>对于为匹配到的，定位background类别</li>
<li>L1损失用于定位，二分交叉熵用于分类</li>
</ol>
<h4 id="多分类损失函数"><a href="#多分类损失函数" class="headerlink" title="多分类损失函数"></a>多分类损失函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 独热编码函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">one_hot_embedding</span>(<span class="params">labels, num_classes</span>):</span><br><span class="line">    <span class="keyword">return</span> torch.eye(num_classes)[labels.data.cpu()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义二分类交叉熵 损失函数</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BCE_Loss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, pred, targ</span>):</span><br><span class="line">        t = one_hot_embedding(targ, self.num_classes+<span class="number">1</span>)</span><br><span class="line">        t = V(t[:,:-<span class="number">1</span>].contiguous())<span class="comment">#.cpu()</span></span><br><span class="line">        x = pred[:,:-<span class="number">1</span>]</span><br><span class="line">        w = self.get_weight(x,t)</span><br><span class="line">        <span class="keyword">return</span> F.binary_cross_entropy_with_logits(x, t, w, size_average=<span class="literal">False</span>)/self.num_classes</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_weight</span>(<span class="params">self,x,t</span>): <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实例化一个损失函数</span></span><br><span class="line">loss_f = BCE_Loss(<span class="built_in">len</span>(Id2Catgris))</span><br></pre></td></tr></table></figure>

<h4 id="IOU-计算（定位损失函数）"><a href="#IOU-计算（定位损失函数）" class="headerlink" title="IOU 计算（定位损失函数）"></a>IOU 计算（定位损失函数）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 交叠区域</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">intersect</span>(<span class="params">box_a, box_b</span>):</span><br><span class="line">    max_xy = torch.<span class="built_in">min</span>(box_a[:, <span class="literal">None</span>, <span class="number">2</span>:], box_b[<span class="literal">None</span>, :, <span class="number">2</span>:])</span><br><span class="line">    min_xy = torch.<span class="built_in">max</span>(box_a[:, <span class="literal">None</span>, :<span class="number">2</span>], box_b[<span class="literal">None</span>, :, :<span class="number">2</span>])</span><br><span class="line">    inter = torch.clamp((max_xy - min_xy), <span class="built_in">min</span>=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> inter[:, :, <span class="number">0</span>] * inter[:, :, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># BBox面积计算</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">box_sz</span>(<span class="params">b</span>): <span class="keyword">return</span> ((b[:, <span class="number">2</span>]-b[:, <span class="number">0</span>]) * (b[:, <span class="number">3</span>]-b[:, <span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># IOU函数(也叫jaccard)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">jaccard</span>(<span class="params">box_a, box_b</span>):</span><br><span class="line">    inter = intersect(box_a, box_b)</span><br><span class="line">    union = box_sz(box_a).unsqueeze(<span class="number">1</span>) + box_sz(box_b).unsqueeze(<span class="number">0</span>) - inter</span><br><span class="line">    <span class="keyword">return</span> inter / union</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回实际存在的目标的BBOX和分类</span></span><br><span class="line"><span class="comment"># 实际上就是去除zero padding</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_y</span>(<span class="params">bbox,clas</span>):</span><br><span class="line"><span class="comment">#     pdb.set_trace()</span></span><br><span class="line">    bbox = bbox.view(-<span class="number">1</span>,<span class="number">4</span>)/sz</span><br><span class="line">    bb_keep = ((bbox[:,<span class="number">2</span>]-bbox[:,<span class="number">0</span>])&gt;<span class="number">0</span>).nonzero()[:,<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> bbox[bb_keep],clas[bb_keep]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测的activations映射到anchor空间的BBox</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">actn_to_bb</span>(<span class="params">actn, anchors</span>):</span><br><span class="line">    <span class="comment"># 缩放成-1~1</span></span><br><span class="line">    actn_bbs = torch.tanh(actn)</span><br><span class="line">    <span class="comment"># 新的BBox中心 </span></span><br><span class="line">    actn_centers = (actn_bbs[:,:<span class="number">2</span>]/<span class="number">2</span> * grid_sizes) + anchors[:,:<span class="number">2</span>] </span><br><span class="line">    <span class="comment"># BBox高宽</span></span><br><span class="line">    actn_hw = (actn_bbs[:,<span class="number">2</span>:]/<span class="number">2</span>+<span class="number">1</span>) * anchors[:,<span class="number">2</span>:]</span><br><span class="line">    <span class="keyword">return</span> hw2corners(actn_centers, actn_hw)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">map_to_ground_truth</span>(<span class="params">overlaps, print_it=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="comment"># max(1)横轴：表示对于每个groundTruth object,哪个anchor覆盖的区域最大，返回最大的值和anchor下标</span></span><br><span class="line">    prior_overlap, prior_idx = overlaps.<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> print_it: <span class="built_in">print</span>(prior_overlap)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># max(0)纵轴：表示对于每个anchor box，在所有groundTruthObject中，最大的覆盖区域和下标（下表表示对象编号）</span></span><br><span class="line">    <span class="comment"># 返回值中的零可能表示重叠区域为零，也有可能表示最大重叠面积的对象下标为0.不过这个后面会通过覆盖比例来筛选的</span></span><br><span class="line">    gt_overlap, gt_idx = overlaps.<span class="built_in">max</span>(<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将gt object对应的anchorbox的重叠置为1.99，设为最大。</span></span><br><span class="line">    gt_overlap[prior_idx] = <span class="number">1.99</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 强行将max(1)这一步中的对应groundtruthobject的几个anchor，在gt_idx中，将他们与ground truth obejct的编号对应上。</span></span><br><span class="line">    <span class="comment"># 有些奇怪，但可能是为了确保万无一失吧</span></span><br><span class="line">    <span class="keyword">for</span> i,o <span class="keyword">in</span> <span class="built_in">enumerate</span>(prior_idx): gt_idx[o] = i </span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> gt_overlap,gt_idx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># SSD中单个目标的损失函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ssd_1_loss</span>(<span class="params">b_c,b_bb,bbox,clas,print_it=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="comment"># 获取实际存在的groundTruth目标（很多时候会充斥0的）</span></span><br><span class="line">    <span class="comment"># 去除Zero Padding</span></span><br><span class="line">    bbox,clas = get_y(bbox,clas) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将预测的bbox与anchor对应上</span></span><br><span class="line">    a_ic = actn_to_bb(b_bb, anchors) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算groundTruth与anchor的重叠</span></span><br><span class="line">    overlaps = jaccard(bbox.data, anchor_cnr.data) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 得到每个anchor值与ground truth object的覆盖面积和对应的object ID</span></span><br><span class="line">    gt_overlap,gt_idx = map_to_ground_truth(overlaps,print_it) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 根据gt_idx索引到分类ID，用于计算分类Loss</span></span><br><span class="line">    gt_clas = clas[gt_idx]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 找到覆盖面积大于阈值的anchor box,进行筛选</span></span><br><span class="line">    pos = gt_overlap &gt; <span class="number">0.4</span></span><br><span class="line">    pos_idx = torch.nonzero(pos)[:,<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># pos不是0就是1，此处将没有分配类别的anchorbox定位背景（bg,下标20）</span></span><br><span class="line">    gt_clas[<span class="number">1</span>-pos] = <span class="built_in">len</span>(Id2Catgris)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># ground truth BBox</span></span><br><span class="line">    gt_bbox = bbox[gt_idx]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 定位损失通过直接计算绝对误差均值</span></span><br><span class="line">    loc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).<span class="built_in">abs</span>()).mean()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 分类误差通过计算二分类交叉熵来计算</span></span><br><span class="line">    clas_loss  = loss_f(b_c, gt_clas)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loc_loss, clas_loss</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SSD损失函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ssd_loss</span>(<span class="params">pred,targ,print_it=<span class="literal">False</span></span>):</span><br><span class="line">    lcs,lls = <span class="number">0.</span>,<span class="number">0.</span></span><br><span class="line">    <span class="keyword">for</span> b_c,b_bb,bbox,clas <span class="keyword">in</span> <span class="built_in">zip</span>(*pred,*targ):</span><br><span class="line">        <span class="comment"># 计算单个的损失</span></span><br><span class="line">        loc_loss,clas_loss = ssd_1_loss(b_c,b_bb,bbox,clas,print_it) </span><br><span class="line">        <span class="comment"># 定位损失</span></span><br><span class="line">        lls += loc_loss  </span><br><span class="line">        <span class="comment"># 分类损失</span></span><br><span class="line">        lcs += clas_loss </span><br><span class="line">    <span class="keyword">if</span> print_it: <span class="built_in">print</span>(<span class="string">f&#x27;loc: <span class="subst">&#123;lls.data[<span class="number">0</span>]&#125;</span>, clas: <span class="subst">&#123;lcs.data[<span class="number">0</span>]&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="comment"># 两者之和作为SSD的损失</span></span><br><span class="line">    <span class="keyword">return</span> lls+lcs </span><br></pre></td></tr></table></figure>

<h3 id="Loss测试"><a href="#Loss测试" class="headerlink" title="Loss测试"></a>Loss测试</h3><p>确保loss函数可行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x,y = <span class="built_in">next</span>(<span class="built_in">iter</span>(md.val_dl))</span><br><span class="line">x,y = V(x),V(y)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i,o <span class="keyword">in</span> <span class="built_in">enumerate</span>(y): y[i] = o.cuda()</span><br><span class="line">learn.model.cuda()</span><br></pre></td></tr></table></figure>




<pre><code>Sequential(
  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
  (2): ReLU(inplace)
  (3): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), ceil_mode=False)
  (4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    )
  )
  (5): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    )
  )
  (6): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    )
  )
  (7): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
      (relu): ReLU(inplace)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
    )
  )
  (8): SSD_Head(
    (drop): Dropout(p=0.25)
    (sconv0): StdConv(
      (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
      (drop): Dropout(p=0.1)
    )
    (sconv2): StdConv(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
      (drop): Dropout(p=0.1)
    )
    (out): OutConv(
      (oconv1): Conv2d(256, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (oconv2): Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">batch = learn.model(x)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssd_loss(batch, y, <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<pre><code> 0.1947
 0.1168
 0.2652
[torch.cuda.FloatTensor of size 3 (GPU 1)]


 0.2885
 0.0888
[torch.cuda.FloatTensor of size 2 (GPU 1)]


...
略
...

1.00000e-02 *
  6.3919
  9.1493
[torch.cuda.FloatTensor of size 2 (GPU 1)]


 0.4062
 0.2180
 0.1307
 0.5762
 0.1524
 0.4794
[torch.cuda.FloatTensor of size 6 (GPU 1)]


 0.1128
[torch.cuda.FloatTensor of size 1 (GPU 1)]

loc: 10.124164581298828, clas: 74.17005157470703





Variable containing:
 84.2942
[torch.cuda.FloatTensor of size 1 (GPU 1)]
</code></pre>
<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">learn.crit = ssd_loss <span class="comment">#指定loss</span></span><br><span class="line">lr = <span class="number">3e-3</span></span><br><span class="line">lrs = np.array([lr/<span class="number">100</span>,lr/<span class="number">10</span>,lr])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">learn.lr_find(lrs/<span class="number">1000</span>,<span class="number">1.</span>)</span><br><span class="line">learn.sched.plot(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<pre><code>epoch      trn_loss   val_loss                            
    0      165.921224 30391.076109
</code></pre>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511060/blog/kpmsygbtdxl5jumrv634.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learn.fit(lr, <span class="number">1</span>, cycle_len=<span class="number">5</span>, use_clr=(<span class="number">20</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure>

<pre><code>epoch      trn_loss   val_loss                            
    0      43.098326  34.007883 
    1      33.96893   28.336332                           
    2      29.650869  26.937769                           
    3      26.758102  26.563267                           
    4      24.590307  26.008181                           



[array([26.00818])]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">learn.save(<span class="string">&#x27;0&#x27;</span>)</span><br><span class="line">learn.load(<span class="string">&#x27;0&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="测试模型"><a href="#测试模型" class="headerlink" title="测试模型"></a>测试模型</h3><h4 id="直接预测"><a href="#直接预测" class="headerlink" title="直接预测"></a>直接预测</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x,y = <span class="built_in">next</span>(<span class="built_in">iter</span>(md.val_dl))</span><br><span class="line">x,y = V(x),V(y)</span><br><span class="line">learn.model.<span class="built_in">eval</span>()</span><br><span class="line">batch = learn.model(x)</span><br><span class="line">b_clas,b_bb = batch</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b_clas.size(),b_bb.size()</span><br></pre></td></tr></table></figure>




<pre><code>(torch.Size([64, 16, 21]), torch.Size([64, 16, 4]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ground truth 一幅图像</span></span><br><span class="line">idx=<span class="number">7</span></span><br><span class="line">b_clasi = b_clas[idx]</span><br><span class="line">b_bboxi = b_bb[idx]</span><br><span class="line">ima=md.val_ds.ds.denorm(to_np(x))[idx]</span><br><span class="line">bbox,clas = get_y(y[<span class="number">0</span>][idx], y[<span class="number">1</span>][idx])</span><br><span class="line">bbox,clas</span><br></pre></td></tr></table></figure>




<pre><code>(Variable containing:
  0.6786  0.4866  0.9911  0.6250
  0.7098  0.0848  0.9911  0.5491
  0.5134  0.8304  0.6696  0.9063
 [torch.cuda.FloatTensor of size 3x4 (GPU 1)], Variable containing:
   8
  10
  17
 [torch.cuda.LongTensor of size 3 (GPU 1)])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个可视化函数（torch下的变量需要转换成numpy）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">torch_gt</span>(<span class="params">ax, ima, bbox, clas, prs=<span class="literal">None</span>, thresh=<span class="number">0.4</span></span>):</span><br><span class="line">    <span class="keyword">return</span> show_ground_truth(ax, ima, to_np((bbox*<span class="number">224</span>).long()),</span><br><span class="line">         to_np(clas), to_np(prs) <span class="keyword">if</span> prs <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span>, thresh)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化ground truth</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">7</span>,<span class="number">7</span>))</span><br><span class="line">torch_gt(ax, ima, bbox, clas)</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511061/blog/qtosj4xvsncebveyy4pe.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化 预测结果</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">7</span>,<span class="number">7</span>))</span><br><span class="line">torch_gt(ax, ima, anchor_cnr, b_clasi.<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511062/blog/eu9ycjxdtpkvjjla08ab.png" alt="png"></p>
<h4 id="过一遍流程，加强理解"><a href="#过一遍流程，加强理解" class="headerlink" title="过一遍流程，加强理解"></a>过一遍流程，加强理解</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grid_sizes</span><br></pre></td></tr></table></figure>




<pre><code>Variable containing:
 0.2500
[torch.cuda.FloatTensor of size 1x1 (GPU 1)]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">anchors</span><br></pre></td></tr></table></figure>




<pre><code>Variable containing:
 0.1250  0.1250  0.2500  0.2500
 0.1250  0.3750  0.2500  0.2500
 0.1250  0.6250  0.2500  0.2500
 0.1250  0.8750  0.2500  0.2500
 0.3750  0.1250  0.2500  0.2500
 0.3750  0.3750  0.2500  0.2500
 0.3750  0.6250  0.2500  0.2500
 0.3750  0.8750  0.2500  0.2500
 0.6250  0.1250  0.2500  0.2500
 0.6250  0.3750  0.2500  0.2500
 0.6250  0.6250  0.2500  0.2500
 0.6250  0.8750  0.2500  0.2500
 0.8750  0.1250  0.2500  0.2500
 0.8750  0.3750  0.2500  0.2500
 0.8750  0.6250  0.2500  0.2500
 0.8750  0.8750  0.2500  0.2500
[torch.cuda.FloatTensor of size 16x4 (GPU 1)]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测得到的BBox，将bbox映射到anchor 空间（共16个）</span></span><br><span class="line">a_ic = actn_to_bb(b_bboxi, anchors)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化预测的结果</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">7</span>,<span class="number">7</span>))</span><br><span class="line">torch_gt(ax, ima, a_ic, b_clasi.<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>], b_clasi.<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">0</span>].sigmoid(), thresh=<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511062/blog/tsh3hfhkcxn8okztpd85.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算IOU（ground truth与anchor box）</span></span><br><span class="line">overlaps = jaccard(bbox.data, anchor_cnr.data)</span><br><span class="line">overlaps</span><br></pre></td></tr></table></figure>




<pre><code>Columns 0 to 9 
 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0091
 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0356  0.0549
 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000

Columns 10 to 15 
 0.0922  0.0000  0.0000  0.0315  0.3985  0.0000
 0.0103  0.0000  0.2598  0.4538  0.0653  0.0000
 0.0000  0.1897  0.0000  0.0000  0.0000  0.0000
[torch.cuda.FloatTensor of size 3x16 (GPU 1)]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 统计anchorBox与ground truth的对应</span></span><br><span class="line">gt_overlap,gt_idx = map_to_ground_truth(overlaps)</span><br><span class="line">gt_overlap,gt_idx</span><br></pre></td></tr></table></figure>




<pre><code>(
  0.0000
  0.0000
  0.0000
  0.0000
  0.0000
  0.0000
  0.0000
  0.0000
  0.0356
  0.0549
  0.0922
  1.9900
  0.2598
  1.9900
  1.9900
  0.0000
 [torch.cuda.FloatTensor of size 16 (GPU 1)], 
  0
  0
  0
  0
  0
  0
  0
  0
  1
  1
  0
  2
  1
  1
  0
  0
 [torch.cuda.LongTensor of size 16 (GPU 1)])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对应的分类标签</span></span><br><span class="line">gt_clas = clas[gt_idx]; gt_clas</span><br></pre></td></tr></table></figure>




<pre><code>Variable containing:
  8
  8
  8
  8
  8
  8
  8
  8
 10
 10
  8
 17
 10
 10
  8
  8
[torch.cuda.LongTensor of size 16 (GPU 1)]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">thresh = <span class="number">0.5</span></span><br><span class="line">pos = gt_overlap &gt; thresh</span><br><span class="line">pos_idx = torch.nonzero(pos)[:,<span class="number">0</span>]</span><br><span class="line">neg_idx = torch.nonzero(<span class="number">1</span>-pos)[:,<span class="number">0</span>]</span><br><span class="line">pos_idx</span><br></pre></td></tr></table></figure>




<pre><code> 11
 13
 14
[torch.cuda.LongTensor of size 3 (GPU 1)]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 给每个anchor box分配分类(注意是ground truth的)</span></span><br><span class="line">gt_clas[<span class="number">1</span>-pos] = <span class="built_in">len</span>(Id2Catgris) <span class="comment"># 没有分类的设为背景bg</span></span><br><span class="line">[Id2Catgris[o] <span class="keyword">if</span> o&lt;<span class="built_in">len</span>(Id2Catgris) <span class="keyword">else</span> <span class="string">&#x27;bg&#x27;</span> <span class="keyword">for</span> o <span class="keyword">in</span> gt_clas.data]</span><br></pre></td></tr></table></figure>




<pre><code>[&#39;bg&#39;,
 &#39;bg&#39;,
 &#39;bg&#39;,
 &#39;bg&#39;,
 &#39;bg&#39;,
 &#39;bg&#39;,
 &#39;bg&#39;,
 &#39;bg&#39;,
 &#39;bg&#39;,
 &#39;bg&#39;,
 &#39;bg&#39;,
 &#39;sofa&#39;,
 &#39;bg&#39;,
 &#39;diningtable&#39;,
 &#39;chair&#39;,
 &#39;bg&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算损失函数</span></span><br><span class="line">gt_bbox = bbox[gt_idx]</span><br><span class="line">loc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).<span class="built_in">abs</span>()).mean()</span><br><span class="line">clas_loss  = F.cross_entropy(b_clasi, gt_clas)</span><br><span class="line">loc_loss,clas_loss</span><br></pre></td></tr></table></figure>




<pre><code>(Variable containing:
 1.00000e-02 *
   6.3615
 [torch.cuda.FloatTensor of size 1 (GPU 1)], Variable containing:
  0.9142
 [torch.cuda.FloatTensor of size 1 (GPU 1)])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化一些预测结果</span></span><br><span class="line">fig, axes = plt.subplots(<span class="number">3</span>, <span class="number">4</span>, figsize=(<span class="number">16</span>, <span class="number">12</span>))</span><br><span class="line"><span class="keyword">for</span> idx,ax <span class="keyword">in</span> <span class="built_in">enumerate</span>(axes.flat):</span><br><span class="line">    ima=md.val_ds.ds.denorm(to_np(x))[idx]</span><br><span class="line">    bbox,clas = get_y(y[<span class="number">0</span>][idx], y[<span class="number">1</span>][idx])</span><br><span class="line">    ima=md.val_ds.ds.denorm(to_np(x))[idx]</span><br><span class="line">    bbox,clas = get_y(bbox,clas); bbox,clas</span><br><span class="line">    a_ic = actn_to_bb(b_bb[idx], anchors)</span><br><span class="line">    torch_gt(ax, ima, a_ic, b_clas[idx].<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>], b_clas[idx].<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">0</span>].sigmoid(), <span class="number">0.01</span>)</span><br><span class="line">plt.tight_layout()</span><br></pre></td></tr></table></figure>

<pre><code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
</code></pre>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511063/blog/vsis5zn1svj9bevxalcw.png" alt="png"></p>
<h2 id="进一步的改进：更多的anchor-box"><a href="#进一步的改进：更多的anchor-box" class="headerlink" title="进一步的改进：更多的anchor box"></a>进一步的改进：更多的anchor box</h2><p>提升的途径：</p>
<ol>
<li>不同大小的Anchor Boxes -&gt; anc_zooms</li>
<li>不同长宽比的Anchor Boxes -&gt; anc_ratios</li>
<li>使用更多的卷积层来产生Anchor Boxes -&gt; anc_grids</li>
</ol>
<h3 id="创建更多的anchor"><a href="#创建更多的anchor" class="headerlink" title="创建更多的anchor"></a>创建更多的anchor</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成anchor的尺寸的查找表</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数列表</span></span><br><span class="line">anc_grids = [<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>]</span><br><span class="line">anc_zooms = [<span class="number">0.7</span>, <span class="number">1.</span>, <span class="number">1.3</span>]</span><br><span class="line">anc_ratios = [(<span class="number">1.</span>,<span class="number">1.</span>), (<span class="number">1.</span>,<span class="number">0.5</span>), (<span class="number">0.5</span>,<span class="number">1.</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成不同尺寸,生成一个LOT查找表</span></span><br><span class="line">anchor_scales = [(anz*i, anz*j) <span class="keyword">for</span> anz <span class="keyword">in</span> anc_zooms <span class="keyword">for</span> (i,j) <span class="keyword">in</span> anc_ratios]</span><br><span class="line"></span><br><span class="line"><span class="comment"># anchor 选项个数</span></span><br><span class="line">k = <span class="built_in">len</span>(anchor_scales)</span><br><span class="line"></span><br><span class="line"><span class="comment"># offsets</span></span><br><span class="line">anc_offsets = [<span class="number">1</span>/(o*<span class="number">2</span>) <span class="keyword">for</span> o <span class="keyword">in</span> anc_grids]</span><br><span class="line"></span><br><span class="line">k</span><br></pre></td></tr></table></figure>




<pre><code>9
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">anc_x = np.concatenate([np.repeat(np.linspace(ao, <span class="number">1</span>-ao,ag),ag) <span class="comment"># 生成anchor 横轴中心</span></span><br><span class="line">                       <span class="keyword">for</span> ao,ag <span class="keyword">in</span> <span class="built_in">zip</span>(anc_offsets, anc_grids)])</span><br><span class="line">anc_y = np.concatenate([np.tile(np.linspace(ao,<span class="number">1</span>-ao,ag), ag)   <span class="comment"># 生成anchor 纵轴中心</span></span><br><span class="line">                       <span class="keyword">for</span> ao,ag <span class="keyword">in</span> <span class="built_in">zip</span>(anc_offsets,anc_grids)])</span><br><span class="line"></span><br><span class="line">anc_ctrs = np.repeat(np.stack([anc_x,anc_y],axis=<span class="number">1</span>),k,axis=<span class="number">0</span>) </span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">anc_sizes  =   np.concatenate([np.array([[o/ag,p/ag] </span><br><span class="line">                                         <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(ag*ag) </span><br><span class="line">                                         <span class="keyword">for</span> o,p <span class="keyword">in</span> anchor_scales]) </span><br><span class="line">                               <span class="keyword">for</span> ag <span class="keyword">in</span> anc_grids])</span><br><span class="line"></span><br><span class="line">grid_sizes = V(np.concatenate([np.array([ <span class="number">1</span>/ag  </span><br><span class="line">                                         <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(ag*ag) </span><br><span class="line">                                         <span class="keyword">for</span> o,p <span class="keyword">in</span> anchor_scales])</span><br><span class="line">                               <span class="keyword">for</span> ag <span class="keyword">in</span> anc_grids]), requires_grad=<span class="literal">False</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算anchor,注意送入GPU</span></span><br><span class="line">anchors = V(np.concatenate([anc_ctrs, anc_sizes], axis=<span class="number">1</span>), requires_grad=<span class="literal">False</span>).<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转换成（左上/右下形式）</span></span><br><span class="line">anchor_cnr = hw2corners(anchors[:,:<span class="number">2</span>],anchors[:,<span class="number">2</span>:])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x,y=to_np(<span class="built_in">next</span>(<span class="built_in">iter</span>(md.val_dl)))</span><br><span class="line">x=md.val_ds.ds.denorm(x)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a=np.reshape((to_np(anchor_cnr) + to_np(torch.randn(*anchor_cnr.size()))*<span class="number">0.01</span>)*<span class="number">224</span>, -<span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">7</span>,<span class="number">7</span>))</span><br><span class="line">show_ground_truth(ax, x[<span class="number">0</span>], a)</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511066/blog/rq9kwshjc7cffthuqibm.png" alt="png"></p>
<h3 id="创建模型"><a href="#创建模型" class="headerlink" title="创建模型"></a>创建模型</h3><p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511066/blog/bcwryesvgselwd9rxw4n.png" alt="image.png"></p>
<p>理一下思路：</p>
<ol>
<li>已经有了GroundTruth（包括4个BBox坐标点和1个分类的集合）；</li>
<li>已经有了一个神经网络可以接收输入图像，并且得到输出activation（激励）；</li>
<li>activations与Ground Truth进行对比，计算loss，然后就是求导更新权重；</li>
<li>【匹配问题】定义的损失函数loss function能够比较activation和ground truth，计算得到的值用于衡量activation的好坏。为此，对于ground  truth中的每个Object，需要决定一组(4+C)的activation与之对比。</li>
<li>因为使用的SSD的方式，所以匹配的anchorBox并不是随意的，用于匹配的activation，其感受野(reception filed)需要与ground truth中的Object所处的位置具有最大的重叠。</li>
<li>匹配问题解决后，即Loss解决后，其他的操作和单目标检测相同。</li>
</ol>
<p>关于参数k的使用：</p>
<p>grid cell可以使不同大小的（anc_grid）,grid cell中可以有不同长宽比和缩放比的anchor box；</p>
<p>anchor box的数目即对应了卷积层activation的组数目，但并不表示每个卷积层需要那么多组activation，因为4x4的卷积层有16组，2x2的卷积层有4组，1x1的卷积层有1组，这样就有了1+4+16组。</p>
<p>接下来只需要知道参数k，k表示的是长宽比和缩放比的组合数。这样，1xk+4xk+16xk，就是全部的anchor box数目了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">drop=<span class="number">0.4</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SSD_MultiHead</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, k, bias</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.drop = nn.Dropout(drop)</span><br><span class="line">        <span class="comment"># stride=1 不改size</span></span><br><span class="line">        self.sconv0 = StdConv(<span class="number">512</span>,<span class="number">256</span>, stride=<span class="number">1</span>, drop=drop)</span><br><span class="line">        <span class="comment"># conv1 4x4</span></span><br><span class="line">        self.sconv1 = StdConv(<span class="number">256</span>,<span class="number">256</span>, drop=drop)</span><br><span class="line">        <span class="comment"># conv2 2x2</span></span><br><span class="line">        self.sconv2 = StdConv(<span class="number">256</span>,<span class="number">256</span>, drop=drop)</span><br><span class="line">        <span class="comment"># conv3 1x1</span></span><br><span class="line">        self.sconv3 = StdConv(<span class="number">256</span>,<span class="number">256</span>, drop=drop)</span><br><span class="line">        self.out0 = OutConv(k, <span class="number">256</span>, bias)</span><br><span class="line">        self.out1 = OutConv(k, <span class="number">256</span>, bias)</span><br><span class="line">        self.out2 = OutConv(k, <span class="number">256</span>, bias)</span><br><span class="line">        self.out3 = OutConv(k, <span class="number">256</span>, bias)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.drop(F.relu(x))</span><br><span class="line">        x = self.sconv0(x)</span><br><span class="line">        x = self.sconv1(x)</span><br><span class="line">        o1c,o1l = self.out1(x) <span class="comment"># 4x4xk</span></span><br><span class="line">        x = self.sconv2(x)</span><br><span class="line">        o2c,o2l = self.out2(x) <span class="comment"># 2x2xk</span></span><br><span class="line">        x = self.sconv3(x)</span><br><span class="line">        o3c,o3l = self.out3(x) <span class="comment"># 1x1xk</span></span><br><span class="line">        <span class="keyword">return</span> [torch.cat([o1c,o2c,o3c], dim=<span class="number">1</span>),</span><br><span class="line">                torch.cat([o1l,o2l,o3l], dim=<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">head_reg4 = SSD_MultiHead(k, -<span class="number">4.</span>)</span><br><span class="line">models = ConvnetBuilder(f_model, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, custom_head=head_reg4)</span><br><span class="line">learn = ConvLearner(md, models)</span><br><span class="line">learn.opt_fn = optim.Adam</span><br></pre></td></tr></table></figure>

<h3 id="训练和测试"><a href="#训练和测试" class="headerlink" title="训练和测试"></a>训练和测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">learn.crit = ssd_loss</span><br><span class="line">lr = <span class="number">1e-2</span></span><br><span class="line">lrs = np.array([lr/<span class="number">100</span>,lr/<span class="number">10</span>,lr])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x,y = <span class="built_in">next</span>(<span class="built_in">iter</span>(md.val_dl))</span><br><span class="line">x,y = V(x),V(y)</span><br><span class="line">batch = learn.model(V(x))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">batch[<span class="number">0</span>].size(),batch[<span class="number">1</span>].size()</span><br></pre></td></tr></table></figure>




<pre><code>(torch.Size([64, 189, 21]), torch.Size([64, 189, 4]))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看loss函数适用</span></span><br><span class="line">ssd_loss(batch, y, <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<pre><code> 0.5598
 0.7922
 0.3095
[torch.cuda.FloatTensor of size 3 (GPU 1)]


 0.6075
 0.7035
[torch.cuda.FloatTensor of size 2 (GPU 1)]


 0.7764
[torch.cuda.FloatTensor of size 1 (GPU 1)]


...
略
...

 0.9778
 0.7173
[torch.cuda.FloatTensor of size 2 (GPU 1)]


 0.4372
 0.5850
 0.2238
 0.5762
 0.6364
 0.4794
[torch.cuda.FloatTensor of size 6 (GPU 1)]


 0.7610
[torch.cuda.FloatTensor of size 1 (GPU 1)]

loc: 7.328256130218506, clas: 325.04620361328125





Variable containing:
 332.3745
[torch.cuda.FloatTensor of size 1 (GPU 1)]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">learn.lr_find(lrs/<span class="number">1000</span>,<span class="number">1.</span>)</span><br><span class="line">learn.sched.plot(n_skip_end=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<pre><code>epoch      trn_loss   val_loss                           
    0      428.072253 7912290.892
</code></pre>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511067/blog/nvhsfugstdvseeszmr3p.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learn.fit(lrs, <span class="number">1</span>, cycle_len=<span class="number">4</span>, use_clr=(<span class="number">20</span>,<span class="number">8</span>))</span><br></pre></td></tr></table></figure>

<pre><code>epoch      trn_loss   val_loss                           
    0      162.041704 142.485135
    1      129.785899 104.201066                         
    2      110.773746 93.877435                          
    3      98.444387  89.302771                          

    
[array([89.30277])]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learn.save(<span class="string">&#x27;tmp&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">learn.freeze_to(-<span class="number">2</span>)</span><br><span class="line">learn.fit(lrs/<span class="number">2</span>, <span class="number">1</span>, cycle_len=<span class="number">4</span>, use_clr=(<span class="number">20</span>,<span class="number">8</span>))</span><br></pre></td></tr></table></figure>

<pre><code>epoch      trn_loss   val_loss                            
    0      91.526261  110.951304
    1      86.313832  88.162423                           
    2      78.734507  82.294672                           
    3      71.840125  77.196213                           


[array([77.19621])]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learn.save(<span class="string">&#x27;prefocal&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试</span></span><br><span class="line">x,y = <span class="built_in">next</span>(<span class="built_in">iter</span>(md.val_dl))</span><br><span class="line">y = V(y)</span><br><span class="line">batch = learn.model(V(x))</span><br><span class="line">b_clas,b_bb = batch</span><br><span class="line">x = to_np(x)</span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(<span class="number">3</span>, <span class="number">4</span>, figsize=(<span class="number">16</span>, <span class="number">12</span>))</span><br><span class="line"><span class="keyword">for</span> idx,ax <span class="keyword">in</span> <span class="built_in">enumerate</span>(axes.flat):</span><br><span class="line">    ima=md.val_ds.ds.denorm(x)[idx]</span><br><span class="line">    bbox,clas = get_y(y[<span class="number">0</span>][idx], y[<span class="number">1</span>][idx])</span><br><span class="line">    a_ic = actn_to_bb(b_bb[idx], anchors)</span><br><span class="line">    torch_gt(ax, ima, a_ic, b_clas[idx].<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>], b_clas[idx].<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">0</span>].sigmoid(), <span class="number">0.21</span>)</span><br><span class="line">plt.tight_layout()</span><br></pre></td></tr></table></figure>

<pre><code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
</code></pre>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511068/blog/uv6kogwva6topimp4jky.png" alt="png"></p>
<p>上面打印出来的是置信度大于0.2的，一些图看起来很有改进空间。</p>
<h2 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h2><p>论文《Focal Loss for Dense Object Detection》<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1708.02002">https://arxiv.org/abs/1708.02002</a></p>
<p>Focal Loss 就是一个解决分类问题中类别不平衡、分类难度差异的一个 loss。</p>
<p>相关博文：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/32423092">《何恺明大神的「Focal Loss」，如何更好地理解？》</a></p>
<h3 id="定义Focal-Loss"><a href="#定义Focal-Loss" class="headerlink" title="定义Focal Loss"></a>定义Focal Loss</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义FocalLoss,基于二分交叉熵进行改进</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FocalLoss</span>(<span class="title class_ inherited__">BCE_Loss</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_weight</span>(<span class="params">self,x,t</span>):</span><br><span class="line">        alpha,gamma = <span class="number">0.25</span>,<span class="number">1</span></span><br><span class="line">        p = x.sigmoid()</span><br><span class="line">        pt = p*t + (<span class="number">1</span>-p)*(<span class="number">1</span>-t)</span><br><span class="line">        w = alpha*t + (<span class="number">1</span>-alpha)*(<span class="number">1</span>-t)</span><br><span class="line">        <span class="keyword">return</span> w * (<span class="number">1</span>-pt).<span class="built_in">pow</span>(gamma)</span><br><span class="line"></span><br><span class="line">loss_f = FocalLoss(<span class="built_in">len</span>(Id2Catgris))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试Loss函数</span></span><br><span class="line">x,y = <span class="built_in">next</span>(<span class="built_in">iter</span>(md.val_dl))</span><br><span class="line">x,y = V(x),V(y)</span><br><span class="line">batch = learn.model(x)</span><br><span class="line">ssd_loss(batch, y, <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<pre><code> 0.5598
 0.7922
 0.3095
[torch.cuda.FloatTensor of size 3 (GPU 1)]


 0.6075
 0.7035
[torch.cuda.FloatTensor of size 2 (GPU 1)]


 0.7764
[torch.cuda.FloatTensor of size 1 (GPU 1)]


...
略
...


 0.9778
 0.7173
[torch.cuda.FloatTensor of size 2 (GPU 1)]


 0.4372
 0.5850
 0.2238
 0.5762
 0.6364
 0.4794
[torch.cuda.FloatTensor of size 6 (GPU 1)]


 0.7610
[torch.cuda.FloatTensor of size 1 (GPU 1)]

loc: 4.548206329345703, clas: 16.757646560668945





Variable containing:
 21.3059
[torch.cuda.FloatTensor of size 1 (GPU 1)]
</code></pre>
<h3 id="训练和测试-1"><a href="#训练和测试-1" class="headerlink" title="训练和测试"></a>训练和测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">learn.lr_find(lrs/<span class="number">1000</span>,<span class="number">1.</span>)</span><br><span class="line">learn.sched.plot(n_skip_end=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<pre><code> 91%|█████████ | 29/32 [00:17&lt;00:01,  1.79it/s, loss=26.2]
</code></pre>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511069/blog/xcu7bpdgeziyocangniv.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learn.fit(lrs, <span class="number">1</span>, cycle_len=<span class="number">10</span>, use_clr=(<span class="number">20</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure>


<pre><code>epoch      trn_loss   val_loss                            
    0      18.807729  34.186557 
    1      20.281371  21.784252                           
    2      19.392129  19.913282                           
    3      18.172636  18.960041                           
    4      16.900487  18.011309                           
    5      15.716368  17.454738                           
    6      14.717347  16.916381                           
    7      13.727865  16.583986                           
    8      12.809763  16.275561                           
    9      12.093133  16.069795                           


[array([16.06979])]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存</span></span><br><span class="line">learn.save(<span class="string">&#x27;fl0&#x27;</span>)</span><br><span class="line">learn.load(<span class="string">&#x27;fl0&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 优化训练</span></span><br><span class="line">learn.freeze_to(-<span class="number">2</span>)</span><br><span class="line">learn.fit(lrs/<span class="number">4</span>, <span class="number">1</span>, cycle_len=<span class="number">10</span>, use_clr=(<span class="number">20</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure>

<pre><code>epoch      trn_loss   val_loss                            
    0      11.201092  16.542418 
    1      11.259083  16.820294                           
    2      11.088501  16.641474                           
    3      10.854862  16.461994                           
    4      10.569602  16.541856                           
    5      10.20212   16.264861                           
    6      9.873908   16.241601                           
    7      9.576044   16.212703                           
    8      9.294867   16.157229                           
    9      9.012196   16.187851                           


[array([16.18785])]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">learn.save(<span class="string">&#x27;drop4&#x27;</span>)</span><br><span class="line">learn.load(<span class="string">&#x27;drop4&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化函数，根据阈值显示预测结果</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_results</span>(<span class="params">thresh</span>):</span><br><span class="line">    x,y = <span class="built_in">next</span>(<span class="built_in">iter</span>(md.val_dl))</span><br><span class="line">    y = V(y)</span><br><span class="line">    batch = learn.model(V(x))</span><br><span class="line">    b_clas,b_bb = batch</span><br><span class="line"></span><br><span class="line">    x = to_np(x)</span><br><span class="line">    fig, axes = plt.subplots(<span class="number">3</span>, <span class="number">4</span>, figsize=(<span class="number">16</span>, <span class="number">12</span>))</span><br><span class="line">    <span class="keyword">for</span> idx,ax <span class="keyword">in</span> <span class="built_in">enumerate</span>(axes.flat):</span><br><span class="line">        ima=md.val_ds.ds.denorm(x)[idx]</span><br><span class="line">        bbox,clas = get_y(y[<span class="number">0</span>][idx], y[<span class="number">1</span>][idx])</span><br><span class="line">        a_ic = actn_to_bb(b_bb[idx], anchors)</span><br><span class="line">        clas_pr, clas_ids = b_clas[idx].<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">        clas_pr = clas_pr.sigmoid()</span><br><span class="line">        torch_gt(ax, ima, a_ic, clas_ids, clas_pr, clas_pr.<span class="built_in">max</span>().data[<span class="number">0</span>]*thresh)</span><br><span class="line">    plt.tight_layout()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_results(<span class="number">0.75</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
</code></pre>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511072/blog/u6gammhuheheimlrh6eg.png" alt="png"></p>
<p>上面的预测已经差不多了，最后一步就是如何筛选出众多选项中最合适的一个作为结果了。也就是非极大抑制。</p>
<h2 id="非极大抑制（NMS）"><a href="#非极大抑制（NMS）" class="headerlink" title="非极大抑制（NMS）"></a>非极大抑制（NMS）</h2><p>按照Howard的说法，NMS好理解，但比较繁琐，他也是直接摘的网上的一段代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义NMS函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">nms</span>(<span class="params">boxes, scores, overlap=<span class="number">0.5</span>, top_k=<span class="number">100</span></span>):</span><br><span class="line">    keep = scores.new(scores.size(<span class="number">0</span>)).zero_().long()</span><br><span class="line">    <span class="keyword">if</span> boxes.numel() == <span class="number">0</span>: <span class="keyword">return</span> keep</span><br><span class="line">    x1 = boxes[:, <span class="number">0</span>]</span><br><span class="line">    y1 = boxes[:, <span class="number">1</span>]</span><br><span class="line">    x2 = boxes[:, <span class="number">2</span>]</span><br><span class="line">    y2 = boxes[:, <span class="number">3</span>]</span><br><span class="line">    area = torch.mul(x2 - x1, y2 - y1)</span><br><span class="line">    v, idx = scores.sort(<span class="number">0</span>)  <span class="comment"># sort in ascending order</span></span><br><span class="line">    idx = idx[-top_k:]  <span class="comment"># indices of the top-k largest vals</span></span><br><span class="line">    xx1 = boxes.new()</span><br><span class="line">    yy1 = boxes.new()</span><br><span class="line">    xx2 = boxes.new()</span><br><span class="line">    yy2 = boxes.new()</span><br><span class="line">    w = boxes.new()</span><br><span class="line">    h = boxes.new()</span><br><span class="line"></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> idx.numel() &gt; <span class="number">0</span>:</span><br><span class="line">        i = idx[-<span class="number">1</span>]  <span class="comment"># index of current largest val</span></span><br><span class="line">        keep[count] = i</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> idx.size(<span class="number">0</span>) == <span class="number">1</span>: <span class="keyword">break</span></span><br><span class="line">        idx = idx[:-<span class="number">1</span>]  <span class="comment"># remove kept element from view</span></span><br><span class="line">        <span class="comment"># load bboxes of next highest vals</span></span><br><span class="line">        torch.index_select(x1, <span class="number">0</span>, idx, out=xx1)</span><br><span class="line">        torch.index_select(y1, <span class="number">0</span>, idx, out=yy1)</span><br><span class="line">        torch.index_select(x2, <span class="number">0</span>, idx, out=xx2)</span><br><span class="line">        torch.index_select(y2, <span class="number">0</span>, idx, out=yy2)</span><br><span class="line">        <span class="comment"># store element-wise max with next highest score</span></span><br><span class="line">        xx1 = torch.clamp(xx1, <span class="built_in">min</span>=x1[i])</span><br><span class="line">        yy1 = torch.clamp(yy1, <span class="built_in">min</span>=y1[i])</span><br><span class="line">        xx2 = torch.clamp(xx2, <span class="built_in">max</span>=x2[i])</span><br><span class="line">        yy2 = torch.clamp(yy2, <span class="built_in">max</span>=y2[i])</span><br><span class="line">        w.resize_as_(xx2)</span><br><span class="line">        h.resize_as_(yy2)</span><br><span class="line">        w = xx2 - xx1</span><br><span class="line">        h = yy2 - yy1</span><br><span class="line">        <span class="comment"># check sizes of xx1 and xx2.. after each iteration</span></span><br><span class="line">        w = torch.clamp(w, <span class="built_in">min</span>=<span class="number">0.0</span>)</span><br><span class="line">        h = torch.clamp(h, <span class="built_in">min</span>=<span class="number">0.0</span>)</span><br><span class="line">        inter = w*h</span><br><span class="line">        <span class="comment"># IoU = i / (area(a) + area(b) - i)</span></span><br><span class="line">        rem_areas = torch.index_select(area, <span class="number">0</span>, idx)  <span class="comment"># load remaining areas)</span></span><br><span class="line">        union = (rem_areas - inter) + area[i]</span><br><span class="line">        IoU = inter/union  <span class="comment"># store result in iou</span></span><br><span class="line">        <span class="comment"># keep only elements with an IoU &lt;= overlap</span></span><br><span class="line">        idx = idx[IoU.le(overlap)]</span><br><span class="line">    <span class="keyword">return</span> keep, count</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试</span></span><br><span class="line">x,y = <span class="built_in">next</span>(<span class="built_in">iter</span>(md.val_dl))</span><br><span class="line">y = V(y)</span><br><span class="line">batch = learn.model(V(x))</span><br><span class="line">b_clas,b_bb = batch</span><br><span class="line">x = to_np(x)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">show_nmf</span>(<span class="params">idx</span>):</span><br><span class="line">    ima=md.val_ds.ds.denorm(x)[idx]</span><br><span class="line">    bbox,clas = get_y(y[<span class="number">0</span>][idx], y[<span class="number">1</span>][idx])</span><br><span class="line">    a_ic = actn_to_bb(b_bb[idx], anchors)</span><br><span class="line">    clas_pr, clas_ids = b_clas[idx].<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">    clas_pr = clas_pr.sigmoid()</span><br><span class="line"></span><br><span class="line">    conf_scores = b_clas[idx].sigmoid().t().data</span><br><span class="line"></span><br><span class="line">    out1,out2,cc = [],[],[]</span><br><span class="line">    <span class="keyword">for</span> cl <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(conf_scores)-<span class="number">1</span>):</span><br><span class="line">        c_mask = conf_scores[cl] &gt; <span class="number">0.25</span></span><br><span class="line">        <span class="keyword">if</span> c_mask.<span class="built_in">sum</span>() == <span class="number">0</span>: <span class="keyword">continue</span></span><br><span class="line">        scores = conf_scores[cl][c_mask]</span><br><span class="line">        l_mask = c_mask.unsqueeze(<span class="number">1</span>).expand_as(a_ic)</span><br><span class="line">        boxes = a_ic[l_mask].view(-<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">        ids, count = nms(boxes.data, scores, <span class="number">0.4</span>, <span class="number">50</span>)</span><br><span class="line">        ids = ids[:count]</span><br><span class="line">        out1.append(scores[ids])</span><br><span class="line">        out2.append(boxes.data[ids])</span><br><span class="line">        cc.append([cl]*count)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> cc:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;i&#125;</span>: empty array&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    cc = T(np.concatenate(cc))</span><br><span class="line">    out1 = torch.cat(out1)</span><br><span class="line">    out2 = torch.cat(out2)</span><br><span class="line"></span><br><span class="line">    fig, ax = plt.subplots(figsize=(<span class="number">8</span>,<span class="number">8</span>))</span><br><span class="line">    torch_gt(ax, ima, out2, cc, out1, <span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>): show_nmf(i)</span><br></pre></td></tr></table></figure>

<pre><code>5: empty array
6: empty array


Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).


10: empty array
</code></pre>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511074/blog/sfs77pk3q1r6np6d8uo0.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511074/blog/nzu2fbaqgrmi38oxwgzo.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511075/blog/rlbuanobuutmhug6gpwb.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511076/blog/ysfwavryof5vyc5y3rr0.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511077/blog/pcazwowwhtiyurhockb5.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511078/blog/esgqtsejxlirskms4eha.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511078/blog/khunfrjqzqqxwsvquj8b.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511079/blog/b6b5uzctq3fk7q03hjsz.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511079/blog/mj26f60dtkuwoc5cntwy.png" alt="png"></p>
<h1 id="End"><a href="#End" class="headerlink" title="End"></a>End</h1><p>效果还是有待提升，先去看SSD 论文了。</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1512.02325">SSD: Single Shot MultiBox Detector</a></p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>xiaohai
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://shenxiaohai.me/fastai-9-objctDetctMulti/" title="在PASCAL VOC数据集上的多目标检测">https://shenxiaohai.me/fastai-9-objctDetctMulti/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" rel="tag"><i class="fa fa-tag"></i> 计算机视觉</a>
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="fa fa-tag"></i> 深度学习</a>
              <a href="/tags/PyTorch/" rel="tag"><i class="fa fa-tag"></i> PyTorch</a>
              <a href="/tags/fast-ai/" rel="tag"><i class="fa fa-tag"></i> fast.ai</a>
              <a href="/tags/SSD/" rel="tag"><i class="fa fa-tag"></i> SSD</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/fastai-8-objctDetct/" rel="prev" title="在PASCAL VOC数据集上的单目标检测">
                  <i class="fa fa-chevron-left"></i> 在PASCAL VOC数据集上的单目标检测
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/paper-SSD/" rel="next" title="SSD 论文阅读笔记">
                  SSD 论文阅读笔记 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments"><div id="twikoo-comments"></div></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2018 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-laptop"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xiaohai</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/veraposeidon" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://shenxiaohai.me/fastai-9-objctDetctMulti/"}</script>
  <script src="/js/third-party/quicklink.js"></script>
<script class="next-config" data-name="twikoo" type="application/json">{"enable":true,"visitor":false,"envId":"https://twikoo-comment.shenxiaohai.me/","el":"#twikoo-comments"}</script>
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.twikoo.el)
    .then(() => NexT.utils.getScript(
      CONFIG.twikoo.jsUrl || 'https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js',
      { condition: window.twikoo }
    ))
    .then(() => {
      twikoo.init(CONFIG.twikoo);
    });
});
</script>
<style>
.post-block, .comments {
  overflow: visible;
}
.tk-owo-emotion {
  display: inline-block;
}
</style>

</body>
</html>
