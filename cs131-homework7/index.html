<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.webp" color="#222">
  <meta name="google-site-verification" content="Cj9oDgXxdJe6MoA_lEUQ2rmOouwJeTm5uJNqjhOv8Ng">
  <meta name="msvalidate.01" content="E5D0AA8F5E012DFD9C5F3954DF8283B1">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,700,700italic%7CNoto+Serif+SC:300,300italic,400,400italic,700,700italic%7CSource+Code+Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"shenxiaohai.me","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.15.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"default"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":"twikoo","storage":true,"lazyload":false,"nav":null,"activeClass":"twikoo"},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="CS131 Computer Vision： Foundations and Applications，Homework7,Object-Detection。 实现人脸检测。使用Hog表征和滑窗法进行人脸检测，使用图像金字塔对尺度问题进行改进，使用DPM(可变形组件模型)进行人脸检测。">
<meta property="og:type" content="article">
<meta property="og:title" content="CS131,Homewrok7,Object-Detection">
<meta property="og:url" content="https://shenxiaohai.me/cs131-homework7/index.html">
<meta property="og:site_name" content="SHEN&#39;s DevNotes">
<meta property="og:description" content="CS131 Computer Vision： Foundations and Applications，Homework7,Object-Detection。 实现人脸检测。使用Hog表征和滑窗法进行人脸检测，使用图像金字塔对尺度问题进行改进，使用DPM(可变形组件模型)进行人脸检测。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511036/blog/kecoxyafdwrzdnnajaku.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511037/blog/eoc10elur4pxvkfzapxv.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511037/blog/gfohym3p7dfjojsp91pq.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511038/blog/wodfchold2wq540xg2gf.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511039/blog/nysw5t7o4dpoqduqpjjc.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511039/blog/xfqzc2aq7d6xxuydibnv.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511040/blog/jxnszyetyi7a0nx9eyxn.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511040/blog/p9dorplajqwtbcnd9une.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511041/blog/xzlztwaj4ojxzpsmifir.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511041/blog/btwehw4x1in57kdmjujx.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511042/blog/tukdxggkuwjx8aftfk3h.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511043/blog/jjaaouy3zofsjdlsmapb.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511043/blog/pzulikn1yhdlrtiivp6u.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511044/blog/fo8jqck9mdaudaopldi0.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511044/blog/jnh865p2qb51lkmiv3nq.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511045/blog/xeuhv0qt9q6jfz1qw0eo.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511045/blog/sn8sr2p2ogchjkpin0df.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511046/blog/zs9tteetj0i4tjlqfqdz.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511046/blog/mxamzsnoslsd41so0udw.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511047/blog/sdgyirpfjx9xztmwnvlv.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511048/blog/xaitnyklyga4stiprylv.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511048/blog/naqc3cxhryelxaymbpfh.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511049/blog/zebp2yccecsvy9s1dhur.png">
<meta property="article:published_time" content="2018-10-06T16:03:03.000Z">
<meta property="article:modified_time" content="2023-03-11T05:04:09.787Z">
<meta property="article:author" content="xiaohai">
<meta property="article:tag" content="计算机视觉">
<meta property="article:tag" content="CS131">
<meta property="article:tag" content="Hog特征">
<meta property="article:tag" content="滑窗法">
<meta property="article:tag" content="图像金字塔">
<meta property="article:tag" content="DPM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511036/blog/kecoxyafdwrzdnnajaku.png">


<link rel="canonical" href="https://shenxiaohai.me/cs131-homework7/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://shenxiaohai.me/cs131-homework7/","path":"cs131-homework7/","title":"CS131,Homewrok7,Object-Detection"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>CS131,Homewrok7,Object-Detection | SHEN's DevNotes</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-YDT7F4NZP6"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"G-YDT7F4NZP6","only_pageview":false}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="SHEN's DevNotes" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">SHEN's DevNotes</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">学习笔记，编程技巧，效率工具</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">135</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">13</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">74</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Homework-7"><span class="nav-text">Homework 7</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Part-1-Hog-Representation-10-points"><span class="nav-text">Part 1: Hog Representation (10 points)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Part-2-Sliding-Window-30-points"><span class="nav-text">Part 2: Sliding Window (30 points)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Part-3-Image-Pyramids-30-points"><span class="nav-text">Part 3: Image Pyramids (30 points)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-Image-Pyramid-10-points"><span class="nav-text">3.1 Image Pyramid (10 points)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-Pyramid-Score-20-points"><span class="nav-text">3.2 Pyramid Score (20 points)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Part-4-Deformable-Parts-Detection"><span class="nav-text">Part 4: Deformable Parts Detection</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Part-5-Human-Parts-Location-10-points"><span class="nav-text">Part 5: Human Parts Location (10 points)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Part-6-Gaussian-Filter-20-points"><span class="nav-text">Part 6: Gaussian Filter (20 points)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Part-6-1-Gaussian-Filter"><span class="nav-text">Part 6.1 Gaussian Filter</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-2-Result-Analysis-10-points"><span class="nav-text">6.2 Result Analysis (10 points)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Extra-Credit-1-point"><span class="nav-text">Extra Credit (1 point)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E6%A1%A3%E6%A1%88"><span class="nav-text">代码档案</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">xiaohai</p>
  <div class="site-description" itemprop="description">我在这个技术博客中分享学习笔记，提供实用技巧和工具资源。</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">74</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">135</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/veraposeidon" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;veraposeidon" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/HiYoake" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;HiYoake" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/big/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://shenxiaohai.me/cs131-homework7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="xiaohai">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SHEN's DevNotes">
      <meta itemprop="description" content="我在这个技术博客中分享学习笔记，提供实用技巧和工具资源。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="CS131,Homewrok7,Object-Detection | SHEN's DevNotes">
      <meta itemprop="description" content="CS131 Computer Vision： Foundations and Applications，Homework7,Object-Detection。<br> 实现人脸检测。<br>使用Hog表征和滑窗法进行人脸检测，<br>使用图像金字塔对尺度问题进行改进，<br>使用DPM(可变形组件模型)进行人脸检测。">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CS131,Homewrok7,Object-Detection
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2018-10-06 16:03:03" itemprop="dateCreated datePublished" datetime="2018-10-06T16:03:03Z">2018-10-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-03-11 05:04:09" itemprop="dateModified" datetime="2023-03-11T05:04:09Z">2023-03-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" itemprop="url" rel="index"><span itemprop="name">计算机视觉</span></a>
        </span>
    </span>

  
</div>

            <div class="post-description">CS131 Computer Vision： Foundations and Applications，Homework7,Object-Detection。<br> 实现人脸检测。<br>使用Hog表征和滑窗法进行人脸检测，<br>使用图像金字塔对尺度问题进行改进，<br>使用DPM(可变形组件模型)进行人脸检测。</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="Homework-7"><a href="#Homework-7" class="headerlink" title="Homework 7"></a>Homework 7</h1><p>In this homework, we will implement a simplified version of object detection process. Note that the tests on the notebook are not comprehensive, autograder will contain more tests.</p>
<p>这份作业是要实现一个简单版本的目标检测流程。</p>
<p>当然，作业里的任务不是很复杂。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> random </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.patches <span class="keyword">as</span> patches</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">from</span> skimage.feature <span class="keyword">import</span> hog</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, color, exposure</span><br><span class="line"><span class="keyword">from</span> skimage.transform <span class="keyword">import</span> rescale, resize, downscale_local_mean</span><br><span class="line"><span class="keyword">import</span> glob, os</span><br><span class="line"><span class="keyword">import</span> fnmatch</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> detection <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> util <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment"># This code is to make matplotlib figures appear inline in the</span></span><br><span class="line"><span class="comment"># notebook rather than in a new window.</span></span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">10.0</span>, <span class="number">8.0</span>) <span class="comment"># set default size of plots</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;image.interpolation&#x27;</span>] = <span class="string">&#x27;nearest&#x27;</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;image.cmap&#x27;</span>] = <span class="string">&#x27;gray&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Some more magic so that the notebook will reload external python modules;</span></span><br><span class="line"><span class="comment"># see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython</span></span><br><span class="line">%load_ext autoreload</span><br><span class="line">%autoreload <span class="number">2</span></span><br><span class="line">%reload_ext autoreload</span><br></pre></td></tr></table></figure>

<h1 id="Part-1-Hog-Representation-10-points"><a href="#Part-1-Hog-Representation-10-points" class="headerlink" title="Part 1: Hog Representation (10 points)"></a>Part 1: Hog Representation (10 points)</h1><p>In this section, we will compute the average hog representation of human faces.<br><br>There are 31 aligned face images provided in the <code>\face</code> folder. They are all aligned and have the same size. We will get an average face from these images and compute a hog feature representation for the averaged face. <br><br>Use the hog function provided by skimage library, and implement a hog representation of objects.<br>Implement <strong><code>hog_feature</code></strong> function in <code>detection.py</code></p>
<p><strong>Hog表征</strong></p>
<p>这里要计算人脸的平均hog表征。可以直接调用skimage包中feature模块内的hog函数进行hog特征的提取。</p>
<blockquote>
<p><strong>博客推荐</strong></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/hujingshuang/article/details/47337707">【特征检测】HOG特征算法</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">image_paths = fnmatch.<span class="built_in">filter</span>(os.listdir(<span class="string">&#x27;./face&#x27;</span>), <span class="string">&#x27;*.jpg&#x27;</span>)</span><br><span class="line"><span class="built_in">list</span>.sort(image_paths)</span><br><span class="line">n = <span class="built_in">len</span>(image_paths)</span><br><span class="line">face_shape = io.imread(<span class="string">&#x27;./face/&#x27;</span>+image_paths[<span class="number">0</span>], as_grey=<span class="literal">True</span>).shape</span><br><span class="line">avg_face= np.zeros((face_shape))</span><br><span class="line"><span class="keyword">for</span> i,image_path <span class="keyword">in</span> <span class="built_in">enumerate</span>(image_paths):</span><br><span class="line">    image = io.imread(<span class="string">&#x27;./face/&#x27;</span>+image_path, as_grey=<span class="literal">True</span>)</span><br><span class="line">    avg_face = np.asarray(image)+np.asarray(avg_face)</span><br><span class="line">avg_face = avg_face/n</span><br><span class="line"></span><br><span class="line">(face_feature, face_hog) = hog_feature(avg_face)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.imshow(avg_face)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;average face image&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.imshow(face_hog)</span><br><span class="line">plt.title(<span class="string">&#x27;hog representation of face&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511036/blog/kecoxyafdwrzdnnajaku.png" alt="png"></p>
<h1 id="Part-2-Sliding-Window-30-points"><a href="#Part-2-Sliding-Window-30-points" class="headerlink" title="Part 2: Sliding Window (30 points)"></a>Part 2: Sliding Window (30 points)</h1><p>Implement <strong><code>sliding_window</code></strong> function to have windows slide across an image with a specific window size. The window slides through the image and check if an object is detected with a high score at every location. These scores will generate a response map and you will be able to find the location of the window with the highest hog score. </p>
<p><strong>滑窗法</strong></p>
<p>滑窗法就是定义一个窗体对象（匹配对象），遍历图像中的图像块，计算卷积响应（此处对两者Hog特征序列进行内积计算），输出值最高的地方就是图像中与匹配对象最相似的地方。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">image_path = <span class="string">&#x27;image_0001.jpg&#x27;</span></span><br><span class="line"></span><br><span class="line">image = io.imread(image_path, as_grey=<span class="literal">True</span>)</span><br><span class="line">image = rescale(image, <span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">(hogFeature, hogImage) = hog_feature(image)</span><br><span class="line"></span><br><span class="line">(winH, winW) = face_shape</span><br><span class="line">(score, r, c, response_map) = sliding_window(image, face_feature, stepSize=<span class="number">30</span>, windowSize=face_shape)</span><br><span class="line">crop = image[r:r+winH, c:c+winW]</span><br><span class="line"></span><br><span class="line">fig,ax = plt.subplots(<span class="number">1</span>)</span><br><span class="line">ax.imshow(image)</span><br><span class="line">rect = patches.Rectangle((c,r),winW,winH,linewidth=<span class="number">1</span>,edgecolor=<span class="string">&#x27;r&#x27;</span>,facecolor=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.add_patch(rect)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.imshow(response_map,cmap=<span class="string">&#x27;viridis&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;sliding window&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511037/blog/eoc10elur4pxvkfzapxv.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511037/blog/gfohym3p7dfjojsp91pq.png" alt="png"></p>
<p>Sliding window successfully found the human face in the above example. However, in the cell below, we are only changing the scale of the image, and you can see that sliding window does not work once the scale of the image is changed. </p>
<p>上面的图像能够检测到人脸的正确区域，但是下面这张图却出现了错误。说明滑窗这种方法对于图像的尺度十分敏感。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">image_path = <span class="string">&#x27;image_0001.jpg&#x27;</span></span><br><span class="line">image = io.imread(image_path, as_grey=<span class="literal">True</span>)</span><br><span class="line">image = rescale(image, <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(winH, winW) = face_shape</span><br><span class="line">(score, r, c, max_response_map) = sliding_window(image, face_feature, stepSize=<span class="number">30</span>, windowSize=face_shape)</span><br><span class="line"></span><br><span class="line">crop = image[r:r+winH, c:c+winW]</span><br><span class="line"></span><br><span class="line">fig,ax = plt.subplots(<span class="number">1</span>)</span><br><span class="line">ax.imshow(image)</span><br><span class="line">rect = patches.Rectangle((c,r),winW,winH,linewidth=<span class="number">1</span>,edgecolor=<span class="string">&#x27;r&#x27;</span>,facecolor=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.add_patch(rect)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.imshow(max_response_map,cmap=<span class="string">&#x27;viridis&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;sliding window&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511038/blog/wodfchold2wq540xg2gf.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511039/blog/nysw5t7o4dpoqduqpjjc.png" alt="png"></p>
<h1 id="Part-3-Image-Pyramids-30-points"><a href="#Part-3-Image-Pyramids-30-points" class="headerlink" title="Part 3: Image Pyramids (30 points)"></a>Part 3: Image Pyramids (30 points)</h1><p>In order to make sliding window work for different scales of images, you need to implement image pyramids where you resize the image to different scales and run the sliding window method on each resized image. This way you scale the objects and can detect both small and large objects. </p>
<p>针对上面的问题，需要采用图像金字塔的方案来进行匹配。</p>
<p>关于图像金字塔，可以看博客。</p>
<blockquote>
<p><strong>博客推荐</strong></p>
<p>[图像金字塔分层算法](<a target="_blank" rel="noopener" href="https://blog.csdn.net/x454045816/article/details/52573637">https://blog.csdn.net/x454045816/article/details/52573637</a></p>
</blockquote>
<p>代码中直接是使用resize函数，生成了不同尺度的图像，具体的图像金字塔实现可以看博客，上采样和下采样是利用高斯滤波器和插值滤波器实现的。</p>
<h3 id="3-1-Image-Pyramid-10-points"><a href="#3-1-Image-Pyramid-10-points" class="headerlink" title="3.1 Image Pyramid (10 points)"></a>3.1 Image Pyramid (10 points)</h3><p>Implement <strong><code>pyramid</code></strong> function in <code>detection.py</code>, this will create pyramid of images at different scales. Run the following code, and you will see the shape of the original image gets smaller until it reaches a minimum size.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">image_path = <span class="string">&#x27;image_0001.jpg&#x27;</span></span><br><span class="line"></span><br><span class="line">image = io.imread(image_path, as_grey=<span class="literal">True</span>)</span><br><span class="line">image = rescale(image, <span class="number">1.2</span>)</span><br><span class="line"></span><br><span class="line">images = pyramid(image, scale = <span class="number">0.9</span>)</span><br><span class="line">sum_r = <span class="number">0</span></span><br><span class="line">sum_c = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i,result <span class="keyword">in</span> <span class="built_in">enumerate</span>(images):</span><br><span class="line">    (scale, image) = result</span><br><span class="line">    <span class="keyword">if</span> (i==<span class="number">0</span>):</span><br><span class="line">        sum_c = image.shape[<span class="number">1</span>]</span><br><span class="line">    sum_r+=image.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">composite_image = np.zeros((sum_r, sum_c))</span><br><span class="line"></span><br><span class="line">pointer = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i, result <span class="keyword">in</span> <span class="built_in">enumerate</span>(images):</span><br><span class="line">    (scale, image) = result   </span><br><span class="line">    composite_image[pointer:pointer+image.shape[<span class="number">0</span>], :image.shape[<span class="number">1</span>]] = image</span><br><span class="line">    pointer+= image.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">plt.imshow(composite_image)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;image pyramid&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511039/blog/xfqzc2aq7d6xxuydibnv.png" alt="png"></p>
<h3 id="3-2-Pyramid-Score-20-points"><a href="#3-2-Pyramid-Score-20-points" class="headerlink" title="3.2 Pyramid Score (20 points)"></a>3.2 Pyramid Score (20 points)</h3><p>After getting the image pyramid, we will run sliding window on all the images to find a place that gets the highest score. Implement <strong><code>pyramid_score</code></strong> function in <code>detection.py</code>. It will return the highest score and its related information in the image pyramids.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">image_path = <span class="string">&#x27;image_0001.jpg&#x27;</span></span><br><span class="line"></span><br><span class="line">image = io.imread(image_path, as_grey=<span class="literal">True</span>)</span><br><span class="line">image = rescale(image, <span class="number">1.4</span>)</span><br><span class="line"></span><br><span class="line">(winH, winW) = face_shape</span><br><span class="line">max_score, maxr, maxc, max_scale, max_response_map = pyramid_score \</span><br><span class="line">        (image, face_feature, face_shape, stepSize = <span class="number">30</span>, scale=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">fig,ax = plt.subplots(<span class="number">1</span>)</span><br><span class="line">ax.imshow(rescale(image, max_scale))</span><br><span class="line">rect = patches.Rectangle((maxc,maxr),winW,winH,linewidth=<span class="number">3</span>,edgecolor=<span class="string">&#x27;r&#x27;</span>,facecolor=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.add_patch(rect)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.imshow(max_response_map, cmap=<span class="string">&#x27;viridis&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511040/blog/jxnszyetyi7a0nx9eyxn.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511040/blog/p9dorplajqwtbcnd9une.png" alt="png"></p>
<p>From the above example, we can see that image pyramid has fixed the problem of scaling. Then in the example below, we will try another image and implement deformable part model.</p>
<p>通过调整<code>image = rescale(image, 1.2)</code>中的缩放比例，可以看到，图像金字塔的方案还是能解决掉上一步中尺度引起的问题的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">image_path = <span class="string">&#x27;image_0338.jpg&#x27;</span></span><br><span class="line">image = io.imread(image_path, as_grey=<span class="literal">True</span>)</span><br><span class="line">image = rescale(image, <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">(winH, winW) = face_shape</span><br><span class="line"></span><br><span class="line">max_score, maxr, maxc, max_scale, max_response_map = pyramid_score \</span><br><span class="line">    (image, face_feature, face_shape, stepSize = <span class="number">30</span>, scale=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">fig,ax = plt.subplots(<span class="number">1</span>)</span><br><span class="line">ax.imshow(rescale(image, max_scale))</span><br><span class="line">rect = patches.Rectangle((maxc,maxr),winW,winH,linewidth=<span class="number">1</span>,edgecolor=<span class="string">&#x27;r&#x27;</span>,facecolor=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.add_patch(rect)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.imshow(max_response_map,cmap=<span class="string">&#x27;viridis&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">    </span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511041/blog/xzlztwaj4ojxzpsmifir.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511041/blog/btwehw4x1in57kdmjujx.png" alt="png"></p>
<p>这张图片的检测貌似没毛病啊。</p>
<h1 id="Part-4-Deformable-Parts-Detection"><a href="#Part-4-Deformable-Parts-Detection" class="headerlink" title="Part 4: Deformable Parts Detection"></a>Part 4: Deformable Parts Detection</h1><p>In order to solve the problem above, you will implement deformable parts model in this section, and apply it on human faces. <br><br>The first step is to get a detector for each part of the face, including left eye, right eye, nose and mouth. <br><br>For example for the left eye, we have provided the groundtruth location of left eyes for each image in the <code>\face</code> directory. This is stored in the <code>lefteyes</code> array with shape <code>(n,2)</code>, each row is the <code>(r,c)</code> location of the center of left eye. You will then find the average hog representation of the left eyes in the images.</p>
<p>关于DPM算法的原理，可以看博客。大致就是跟模型的检测和组件模型的检测，然后求响应值。</p>
<blockquote>
<p><strong>博客推荐</strong></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_14845119/article/details/52625426">DPM（Deformable Part Model）原理详解</a></p>
</blockquote>
<p>下面四块分别是左眼、右眼、鼻子和眼镜的检测器。</p>
<p>代码是作业本身就提供了的，不过可以仔细研究一下具体实现。</p>
<p>Run through the following code to get a detector for left eyes.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">image_paths = fnmatch.<span class="built_in">filter</span>(os.listdir(<span class="string">&#x27;./face&#x27;</span>), <span class="string">&#x27;*.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line">parts = read_facial_labels(image_paths)</span><br><span class="line">lefteyes, righteyes, noses, mouths = parts</span><br><span class="line"></span><br><span class="line"><span class="comment"># Typical shape for left eye</span></span><br><span class="line">lefteye_h = <span class="number">10</span></span><br><span class="line">lefteye_w = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">lefteye_shape = (lefteye_h, lefteye_w)</span><br><span class="line"></span><br><span class="line">avg_lefteye = get_detector(lefteye_h, lefteye_w, lefteyes, image_paths)</span><br><span class="line">(lefteye_feature, lefteye_hog) = hog_feature(avg_lefteye, pixel_per_cell=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">plt.imshow(avg_lefteye)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;average left eye image&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">plt.imshow(lefteye_hog)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;average hog image&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511042/blog/tukdxggkuwjx8aftfk3h.png" alt="png"></p>
<p>Run through the following code to get a detector for right eye.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">righteye_h = <span class="number">10</span></span><br><span class="line">righteye_w = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">righteye_shape = (righteye_h, righteye_w)</span><br><span class="line"></span><br><span class="line">avg_righteye = get_detector(righteye_h, righteye_w, righteyes, image_paths)</span><br><span class="line"></span><br><span class="line">(righteye_feature, righteye_hog) = hog_feature(avg_righteye, pixel_per_cell=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">plt.imshow(avg_righteye)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;average right eye image&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">plt.imshow(righteye_hog)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;average hog image&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511043/blog/jjaaouy3zofsjdlsmapb.png" alt="png"></p>
<p>Run through the following code to get a detector for nose.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">nose_h = <span class="number">30</span></span><br><span class="line">nose_w = <span class="number">26</span></span><br><span class="line"></span><br><span class="line">nose_shape = (nose_h, nose_w)</span><br><span class="line"></span><br><span class="line">avg_nose = get_detector(nose_h, nose_w, noses, image_paths)</span><br><span class="line"></span><br><span class="line">(nose_feature, nose_hog) = hog_feature(avg_nose, pixel_per_cell=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">plt.imshow(avg_nose)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;average nose image&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">plt.imshow(nose_hog)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;average hog image&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511043/blog/pzulikn1yhdlrtiivp6u.png" alt="png"></p>
<p>Run through the following code to get a detector for mouth</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">mouth_h = <span class="number">20</span></span><br><span class="line">mouth_w = <span class="number">36</span></span><br><span class="line"></span><br><span class="line">mouth_shape = (mouth_h, mouth_w)</span><br><span class="line"></span><br><span class="line">avg_mouth = get_detector(mouth_h, mouth_w, mouths, image_paths)</span><br><span class="line"></span><br><span class="line">(mouth_feature, mouth_hog) = hog_feature(avg_mouth, pixel_per_cell=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">detectors_list = [lefteye_feature, righteye_feature, nose_feature, mouth_feature]</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">plt.imshow(avg_mouth)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;average mouth image&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line">plt.imshow(mouth_hog)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;average hog image&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511044/blog/fo8jqck9mdaudaopldi0.png" alt="png"></p>
<h1 id="Part-5-Human-Parts-Location-10-points"><a href="#Part-5-Human-Parts-Location-10-points" class="headerlink" title="Part 5: Human Parts Location (10 points)"></a>Part 5: Human Parts Location (10 points)</h1><p>Implement <strong><code>compute_displacement</code></strong> to get an average shift vector mu and standard deviation sigma for each part of the face. The vector mu is the distance from the main center, i.e the center of the face, to the center of the part. <br></p>
<p><strong>找到各个部位的位置</strong></p>
<p>这里计算的是相对位置，即各个组件的中心与脸部中心的距离。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test for compute_displacement</span></span><br><span class="line">test_array = np.array([[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">3</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line">test_shape = (<span class="number">6</span>,<span class="number">6</span>)</span><br><span class="line">mu, std = compute_displacement(test_array, test_shape)</span><br><span class="line"><span class="keyword">assert</span>(np.<span class="built_in">all</span>(mu == [<span class="number">1</span>,<span class="number">0</span>]))</span><br><span class="line"><span class="keyword">assert</span>(np.<span class="built_in">sum</span>(std-[ <span class="number">1.11803399</span>,  <span class="number">1.11803399</span>])&lt;<span class="number">1e-5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Your implementation is correct!&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Your implementation is correct!
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lefteye_mu, lefteye_std = compute_displacement(lefteyes, face_shape)</span><br><span class="line">righteye_mu, righteye_std = compute_displacement(righteyes, face_shape)</span><br><span class="line">nose_mu, nose_std = compute_displacement(noses, face_shape)</span><br><span class="line">mouth_mu, mouth_std = compute_displacement(mouths, face_shape)</span><br></pre></td></tr></table></figure>

<p>After getting the shift vectors, we can run our detector on a test image. We will first run the following code to detect each part of left eye, right eye, nose and mouth in  the image. You will see a response map for each of them.</p>
<p>分别使用脸部和各个组件的检测器，对整张图像进行匹配计算，得到每个组件的响应图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">image_path = <span class="string">&#x27;image_0338.jpg&#x27;</span></span><br><span class="line">image = io.imread(image_path, as_grey=<span class="literal">True</span>)</span><br><span class="line">image = rescale(image, <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">(face_H, face_W) = face_shape</span><br><span class="line">max_score, face_r, face_c, face_scale, face_response_map = pyramid_score\</span><br><span class="line">    (image, face_feature, face_shape,stepSize = <span class="number">30</span>, scale=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line">plt.imshow(face_response_map, cmap=<span class="string">&#x27;viridis&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511044/blog/jnh865p2qb51lkmiv3nq.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">max_score, lefteye_r, lefteye_c, lefteye_scale, lefteye_response_map = \</span><br><span class="line">    pyramid_score(image, lefteye_feature,lefteye_shape, stepSize = <span class="number">20</span>,scale=<span class="number">0.9</span>, pixel_per_cell = <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">lefteye_response_map = resize(lefteye_response_map, face_response_map.shape)</span><br><span class="line"></span><br><span class="line">plt.imshow(lefteye_response_map,cmap=<span class="string">&#x27;viridis&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511045/blog/xeuhv0qt9q6jfz1qw0eo.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">max_score, righteye_r, righteye_c, righteye_scale, righteye_response_map = \</span><br><span class="line">    pyramid_score (image, righteye_feature, righteye_shape, stepSize = <span class="number">20</span>,scale=<span class="number">0.9</span>, pixel_per_cell=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">righteye_response_map = resize(righteye_response_map, face_response_map.shape)</span><br><span class="line"></span><br><span class="line">plt.imshow(righteye_response_map,cmap=<span class="string">&#x27;viridis&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511045/blog/sn8sr2p2ogchjkpin0df.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">max_score, nose_r, nose_c, nose_scale, nose_response_map = \</span><br><span class="line">    pyramid_score (image, nose_feature, nose_shape, stepSize = <span class="number">20</span>,scale=<span class="number">0.9</span>, pixel_per_cell = <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">nose_response_map = resize(nose_response_map, face_response_map.shape)</span><br><span class="line"></span><br><span class="line">plt.imshow(nose_response_map,cmap=<span class="string">&#x27;viridis&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511046/blog/zs9tteetj0i4tjlqfqdz.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">max_score, mouth_r, mouth_c, mouth_scale, mouth_response_map =\</span><br><span class="line">    pyramid_score (image, mouth_feature, mouth_shape, stepSize = <span class="number">20</span>,scale=<span class="number">0.9</span>, pixel_per_cell = <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">mouth_response_map = resize(mouth_response_map, face_response_map.shape)</span><br><span class="line">plt.imshow(mouth_response_map,cmap=<span class="string">&#x27;viridis&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511046/blog/mxamzsnoslsd41so0udw.png" alt="png"></p>
<p>After getting the response maps for each part of the face, we will shift these maps so that they all have the same center as the face. We have calculated the shift vector mu in <code>compute_displacement</code>, so we are shifting based on vector mu. Implement <code>shift_heatmap</code> function in <code>detection.py</code>.</p>
<p>得到各个组件的响应图之后，移动这些响应图，使得它们的中心和脸部的中心相同，方便求和。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">face_heatmap_shifted = shift_heatmap(face_response_map, [<span class="number">0</span>,<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">lefteye_heatmap_shifted = shift_heatmap(lefteye_response_map, lefteye_mu)</span><br><span class="line">righteye_heatmap_shifted = shift_heatmap(righteye_response_map, righteye_mu)</span><br><span class="line">nose_heatmap_shifted = shift_heatmap(nose_response_map, nose_mu)</span><br><span class="line">mouth_heatmap_shifted = shift_heatmap(mouth_response_map, mouth_mu)</span><br><span class="line"></span><br><span class="line">f, axarr = plt.subplots(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">axarr[<span class="number">0</span>,<span class="number">0</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">axarr[<span class="number">0</span>,<span class="number">1</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">axarr[<span class="number">1</span>,<span class="number">0</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">axarr[<span class="number">1</span>,<span class="number">1</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">axarr[<span class="number">0</span>,<span class="number">0</span>].imshow(lefteye_heatmap_shifted,cmap=<span class="string">&#x27;viridis&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">axarr[<span class="number">0</span>,<span class="number">1</span>].imshow(righteye_heatmap_shifted,cmap=<span class="string">&#x27;viridis&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">axarr[<span class="number">1</span>,<span class="number">0</span>].imshow(nose_heatmap_shifted,cmap=<span class="string">&#x27;viridis&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">axarr[<span class="number">1</span>,<span class="number">1</span>].imshow(mouth_heatmap_shifted,cmap=<span class="string">&#x27;viridis&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511047/blog/sdgyirpfjx9xztmwnvlv.png" alt="png"></p>
<h1 id="Part-6-Gaussian-Filter-20-points"><a href="#Part-6-Gaussian-Filter-20-points" class="headerlink" title="Part 6: Gaussian Filter (20 points)"></a>Part 6: Gaussian Filter (20 points)</h1><h2 id="Part-6-1-Gaussian-Filter"><a href="#Part-6-1-Gaussian-Filter" class="headerlink" title="Part 6.1 Gaussian Filter"></a>Part 6.1 Gaussian Filter</h2><p>In this part, apply gaussian filter convolution to each heatmap. Blur by kernel of standard deviation sigma, and then add the heatmaps of the parts with the heatmap of the face. On the combined heatmap, find the maximum value and its location. You can use function provided by skimage to implement <strong><code>gaussian_heatmap</code></strong>.</p>
<p>这个部分呢，就是将之前的各个组件的响应图给叠加起来，然后判断图像区域内哪个点的响应最大，则该处判断为人脸区域。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">heatmap_face= face_heatmap_shifted</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里将各个组件构建数组，传入</span></span><br><span class="line">heatmaps = [lefteye_heatmap_shifted, </span><br><span class="line">           righteye_heatmap_shifted,</span><br><span class="line">           nose_heatmap_shifted,</span><br><span class="line">           mouth_heatmap_shifted]</span><br><span class="line">sigmas = [lefteye_std, righteye_std, nose_std, mouth_std]</span><br><span class="line"></span><br><span class="line">heatmap, i , j = gaussian_heatmap(heatmap_face, heatmaps, sigmas)</span><br><span class="line"></span><br><span class="line">fig,ax = plt.subplots(<span class="number">1</span>)</span><br><span class="line">rect = patches.Rectangle((j-winW//<span class="number">2</span>, i-winH//<span class="number">2</span>),winW,winH,linewidth=<span class="number">1</span>,edgecolor=<span class="string">&#x27;r&#x27;</span>,facecolor=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.add_patch(rect)</span><br><span class="line"></span><br><span class="line">plt.imshow(heatmap,cmap=<span class="string">&#x27;viridis&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">fig,ax = plt.subplots(<span class="number">1</span>)</span><br><span class="line">rect = patches.Rectangle((j-winW//<span class="number">2</span>, i-winH//<span class="number">2</span>),winW,winH,linewidth=<span class="number">1</span>,edgecolor=<span class="string">&#x27;r&#x27;</span>,facecolor=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.add_patch(rect)</span><br><span class="line"></span><br><span class="line">plt.imshow(resize(image, heatmap.shape))</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511048/blog/xaitnyklyga4stiprylv.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511048/blog/naqc3cxhryelxaymbpfh.png" alt="png"></p>
<h2 id="6-2-Result-Analysis-10-points"><a href="#6-2-Result-Analysis-10-points" class="headerlink" title="6.2 Result Analysis (10 points)"></a>6.2 Result Analysis (10 points)</h2><p>Does your DPM work on detecting human faces? Can you think of a case where DPM may work better than the detector we had in part 3 (sliding window + image pyramid)? You can also have examples that are not faces.</p>
<p>DPM的原理是很能理解的，就是将各个组件的响应值累加起来，判断哪个区域拥有最高的响应值。</p>
<p>上图的检测出现了问题，怀疑是脸部组件的检测不咋滴。</p>
<p><strong>Your Answer:</strong> Write your answer in this markdown cell.</p>
<h2 id="Extra-Credit-1-point"><a href="#Extra-Credit-1-point" class="headerlink" title="Extra Credit (1 point)"></a>Extra Credit (1 point)</h2><p>You have tried detecting one face from the image, and the next step is to extend it to detecting multiple occurences of the object. For example in the following image, how do you detect more than one face from your response map? Implement the function <strong><code>detect_multiple</code></strong>, and write code to visualize your detected faces in the cell below.</p>
<p>没有好思路啊，唯一有的就是检测到一张人脸，就将该区域置为白色或黑色。</p>
<p>可是上一步的DPM算法效果貌似不行，不想往下进行下去了。先做第八份作业吧。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">image_path = <span class="string">&#x27;image_0002.jpg&#x27;</span></span><br><span class="line">image = io.imread(image_path, as_grey=<span class="literal">True</span>)</span><br><span class="line">plt.imshow(image)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511049/blog/zebp2yccecsvy9s1dhur.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">image_path = <span class="string">&#x27;image_0002.jpg&#x27;</span></span><br><span class="line">image = io.imread(image_path, as_grey=<span class="literal">True</span>)</span><br><span class="line">heatmap = get_heatmap (image,face_feature, face_shape,detectors_list, parts )</span><br><span class="line"></span><br><span class="line">plt.imshow(heatmap, cmap=<span class="string">&#x27;viridis&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">detected_faces = detect_multiple(image, heatmap)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Visualize your detected faces</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### YOUR CODE HERE</span></span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"><span class="comment">### END YOUR CODE</span></span><br></pre></td></tr></table></figure>



<h1 id="代码档案"><a href="#代码档案" class="headerlink" title="代码档案"></a>代码档案</h1><p><a target="_blank" rel="noopener" href="https://github.com/StanfordVL/CS131_release/tree/master/hw7_release">官方Repo作业材料</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/veraposeidon/CS131_Assignments/tree/master/hw7_release">个人Repo作业存档</a></p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>xiaohai
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://shenxiaohai.me/cs131-homework7/" title="CS131,Homewrok7,Object-Detection">https://shenxiaohai.me/cs131-homework7/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" rel="tag"><i class="fa fa-tag"></i> 计算机视觉</a>
              <a href="/tags/CS131/" rel="tag"><i class="fa fa-tag"></i> CS131</a>
              <a href="/tags/Hog%E7%89%B9%E5%BE%81/" rel="tag"><i class="fa fa-tag"></i> Hog特征</a>
              <a href="/tags/%E6%BB%91%E7%AA%97%E6%B3%95/" rel="tag"><i class="fa fa-tag"></i> 滑窗法</a>
              <a href="/tags/%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94/" rel="tag"><i class="fa fa-tag"></i> 图像金字塔</a>
              <a href="/tags/DPM/" rel="tag"><i class="fa fa-tag"></i> DPM</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/cs131-homework6/" rel="prev" title="CS131,Homewrok6,Recognition-Classification">
                  <i class="fa fa-chevron-left"></i> CS131,Homewrok6,Recognition-Classification
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/cs131-homework8/" rel="next" title="CS131,Homewrok8,Tracking-OpticalFlow">
                  CS131,Homewrok8,Tracking-OpticalFlow <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments"><div id="twikoo-comments"></div></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2018 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-laptop"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xiaohai</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/veraposeidon" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://shenxiaohai.me/cs131-homework7/"}</script>
  <script src="/js/third-party/quicklink.js"></script>
<script class="next-config" data-name="twikoo" type="application/json">{"enable":true,"visitor":false,"envId":"https://twikoo-comment.shenxiaohai.me/","el":"#twikoo-comments"}</script>
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.twikoo.el)
    .then(() => NexT.utils.getScript(
      CONFIG.twikoo.jsUrl || 'https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js',
      { condition: window.twikoo }
    ))
    .then(() => {
      twikoo.init(CONFIG.twikoo);
    });
});
</script>
<style>
.post-block, .comments {
  overflow: visible;
}
.tk-owo-emotion {
  display: inline-block;
}
</style>

</body>
</html>
