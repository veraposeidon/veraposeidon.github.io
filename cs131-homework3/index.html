<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.webp" color="#222">
  <meta name="google-site-verification" content="Cj9oDgXxdJe6MoA_lEUQ2rmOouwJeTm5uJNqjhOv8Ng">
  <meta name="msvalidate.01" content="E5D0AA8F5E012DFD9C5F3954DF8283B1">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,700,700italic%7CNoto+Serif+SC:300,300italic,400,400italic,700,700italic%7CSource+Code+Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"shenxiaohai.me","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.15.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"default"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":"twikoo","storage":true,"lazyload":false,"nav":null,"activeClass":"twikoo"},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="CS131 Computer Vision： Foundations and Applications，Homework3：Edges-Smart Car Lane Detection。 重点在理解Harris角点检测，HOG描述符，图像匹配，以及RANSAC随机抽样一致，估计仿射变换矩阵，最终实现全景图像拼接。">
<meta property="og:type" content="article">
<meta property="og:title" content="CS131,Homewrok3,Panorama-ImageStiching">
<meta property="og:url" content="https://shenxiaohai.me/cs131-homework3/index.html">
<meta property="og:site_name" content="SHEN&#39;s DevNotes">
<meta property="og:description" content="CS131 Computer Vision： Foundations and Applications，Homework3：Edges-Smart Car Lane Detection。 重点在理解Harris角点检测，HOG描述符，图像匹配，以及RANSAC随机抽样一致，估计仿射变换矩阵，最终实现全景图像拼接。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511005/blog/mzdcjzwwa5t8pdt2snag.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511007/blog/s5k4bvnsxywgxrtbjjue.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511007/blog/qqtkqyphsb72aqtdpvq8.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511008/blog/llezbmkgrhos3ctjfonp.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511009/blog/gzfo0pxnwoc0nmkx9ehc.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511009/blog/xxarzwoja3cxmiijiqi0.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511010/blog/rk9qthgo7rhtngfd9zbu.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511010/blog/e0oacasoqtakwkpue78f.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511011/blog/ffsybwtoobpk3g5smj2b.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511012/blog/n0oeo039lahckbe8d4kr.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511012/blog/jwara3fcmqhqieuobyjt.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511013/blog/y5a4rh2ux3o7uhqppzsf.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511013/blog/qepn9o4wkx5zqyvveae8.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511014/blog/yyb7mpgvcbq08ug6zrxb.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511015/blog/bozuu1b3sslcidzaxwqz.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511015/blog/o8apwrewmgvielqollfe.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511016/blog/c8y65hm6tini3jal2x3o.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511016/blog/dpouua5dmhntazssxlyk.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511017/blog/ulrryjjjyvsyrh1pvqc6.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511018/blog/eskritbf1zow10xtrmdw.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511019/blog/f5kkmnar1r4oiedxrvf3.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511019/blog/bbeyop2feswslpohzfdi.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511020/blog/ht3zlfqyufjax4pfhpjf.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511020/blog/xmt9i3mcxb306simvph0.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511021/blog/pkksviadsttuvdfxjhdh.png">
<meta property="og:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511021/blog/nv3ut1javufs5kqciefi.png">
<meta property="article:published_time" content="2018-09-07T09:43:22.000Z">
<meta property="article:modified_time" content="2023-04-02T14:33:34.696Z">
<meta property="article:author" content="xiaohai">
<meta property="article:tag" content="计算机视觉">
<meta property="article:tag" content="CS131">
<meta property="article:tag" content="图像拼接">
<meta property="article:tag" content="角点检测">
<meta property="article:tag" content="RANSAC">
<meta property="article:tag" content="HOG描述子">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511005/blog/mzdcjzwwa5t8pdt2snag.png">


<link rel="canonical" href="https://shenxiaohai.me/cs131-homework3/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://shenxiaohai.me/cs131-homework3/","path":"cs131-homework3/","title":"CS131,Homewrok3,Panorama-ImageStiching"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>CS131,Homewrok3,Panorama-ImageStiching | SHEN's DevNotes</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-YDT7F4NZP6"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"G-YDT7F4NZP6","only_pageview":false}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="SHEN's DevNotes" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">SHEN's DevNotes</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">学习笔记，编程技巧，效率工具</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">135</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">13</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">74</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Homework-3"><span class="nav-text">Homework 3</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-Panorama-Stitching-%EF%BC%9A%E5%85%A8%E6%99%AF%E6%8B%BC%E6%8E%A5"><span class="nav-text">Introduction: Panorama Stitching ：全景拼接</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part-1-Harris-Corner-Detector-20-points"><span class="nav-text">Part 1 Harris Corner Detector (20 points)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part-2-Describing-and-Matching-Keypoints-20-points"><span class="nav-text">Part 2 Describing and Matching Keypoints (20 points)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Part-2-1-Creating-Descriptors-10-points"><span class="nav-text">Part 2.1 Creating Descriptors (10 points)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Part-2-2-Matching-Descriptors-10-points"><span class="nav-text">Part 2.2 Matching Descriptors (10 points)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part-3-Transformation-Estimation-20-points"><span class="nav-text">Part 3 Transformation Estimation (20 points)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part-4-RANSAC-20-points"><span class="nav-text">Part 4 RANSAC (20 points)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Part-5-Histogram-of-Oriented-Gradients-HOG-20-points"><span class="nav-text">Part 5 Histogram of Oriented Gradients (HOG) (20 points)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Extra-Credit-Better-Image-Merging"><span class="nav-text">Extra Credit: Better Image Merging</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Extra-Credit-Stitching-Multiple-Images"><span class="nav-text">Extra Credit: Stitching Multiple Images</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E6%A1%A3%E6%A1%88"><span class="nav-text">代码档案</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">xiaohai</p>
  <div class="site-description" itemprop="description">我在这个技术博客中分享学习笔记，提供实用技巧和工具资源。</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">74</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">135</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/veraposeidon" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;veraposeidon" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/HiYoake" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;HiYoake" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/big/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://shenxiaohai.me/cs131-homework3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="xiaohai">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SHEN's DevNotes">
      <meta itemprop="description" content="我在这个技术博客中分享学习笔记，提供实用技巧和工具资源。">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="CS131,Homewrok3,Panorama-ImageStiching | SHEN's DevNotes">
      <meta itemprop="description" content="CS131 Computer Vision： Foundations and Applications，Homework3：Edges-Smart Car Lane Detection。<br> 重点在理解Harris角点检测，HOG描述符，图像匹配，以及RANSAC随机抽样一致，估计仿射变换矩阵，最终实现全景图像拼接。">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CS131,Homewrok3,Panorama-ImageStiching
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2018-09-07 09:43:22" itemprop="dateCreated datePublished" datetime="2018-09-07T09:43:22Z">2018-09-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-02 14:33:34" itemprop="dateModified" datetime="2023-04-02T14:33:34Z">2023-04-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" itemprop="url" rel="index"><span itemprop="name">计算机视觉</span></a>
        </span>
    </span>

  
</div>

            <div class="post-description">CS131 Computer Vision： Foundations and Applications，Homework3：Edges-Smart Car Lane Detection。<br> 重点在理解Harris角点检测，HOG描述符，图像匹配，以及RANSAC随机抽样一致，估计仿射变换矩阵，最终实现全景图像拼接。</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="Homework-3"><a href="#Homework-3" class="headerlink" title="Homework 3"></a>Homework 3</h1><p>This assignment covers Harris corner detector, RANSAC and HOG descriptor.</p>
<p>这份作业涵盖的知识点有：</p>
<ul>
<li>Harris 角点检测器</li>
<li>RANSAC 随机抽样一致</li>
<li>HOG 描述子</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="comment"># Setup</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> filters</span><br><span class="line"><span class="keyword">from</span> skimage.feature <span class="keyword">import</span> corner_peaks</span><br><span class="line"><span class="keyword">from</span> skimage.io <span class="keyword">import</span> imread</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">15.0</span>, <span class="number">12.0</span>) <span class="comment"># set default size of plots</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;image.interpolation&#x27;</span>] = <span class="string">&#x27;nearest&#x27;</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;image.cmap&#x27;</span>] = <span class="string">&#x27;gray&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#有中文出现的情况，需要u&#x27;内容&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># for auto-reloading extenrnal modules</span></span><br><span class="line">%load_ext autoreload</span><br><span class="line">%autoreload <span class="number">2</span></span><br></pre></td></tr></table></figure>

<pre><code>The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
</code></pre>
<h2 id="Introduction-Panorama-Stitching-：全景拼接"><a href="#Introduction-Panorama-Stitching-：全景拼接" class="headerlink" title="Introduction: Panorama Stitching ：全景拼接"></a>Introduction: Panorama Stitching ：全景拼接</h2><p>Panorama stitching is an early success of computer vision. Matthew Brown and David G. Lowe published a famous <a target="_blank" rel="noopener" href="http://matthewalunbrown.com/papers/ijcv2007.pdf">panoramic image stitching paper</a> in 2007. Since then, automatic panorama stitching technology has been widely adopted in many applications such as Google Street View, panorama photos on smartphones,<br>and stitching software such as Photosynth and AutoStitch.</p>
<p>In this assignment, we will detect and match keypoints from multiple images to build a single panoramic image. This will involve several tasks:</p>
<ol>
<li>Use Harris corner detector to find keypoints.</li>
<li>Build a descriptor to describe each point in an image. <br><br>Compare two sets of descriptors coming from two different images and find matching keypoints.</li>
<li>Given a list of matching keypoints, use least-squares method to find the affine transformation matrix that maps points in one image to another.</li>
<li>Use RANSAC to give a more robust estimate of affine transformation matrix. <br><br>Given the transformation matrix, use it to transform the second image and overlay it on the first image, forming a panorama.</li>
<li>Implement a different descriptor (HOG descriptor) and get another stitching result.</li>
</ol>
<p>步骤如下：</p>
<ol>
<li>使用Harris焦点检测器寻找关键点。</li>
<li>构建描述算子来描述图中的每个关键点， <br> 比较两幅图像的两组描述子，并进行匹配。</li>
<li>根据一组匹配关键点，使用最小二乘法进行仿射变换矩阵的计算。</li>
<li>使用RANSAC计算一个更加稳定的仿射变换的矩阵， <br> 然后将第二幅图变换过来并覆盖在第一幅图上，形成一个全景。</li>
<li>实现不同的描述子，并得到不同的拼接结果。</li>
</ol>
<h2 id="Part-1-Harris-Corner-Detector-20-points"><a href="#Part-1-Harris-Corner-Detector-20-points" class="headerlink" title="Part 1 Harris Corner Detector (20 points)"></a>Part 1 Harris Corner Detector (20 points)</h2><p>In this section, you are going to implement Harris corner detector for keypoint localization. Review the lecture slides on Harris corner detector to understand how it works. The Harris detection algorithm can be divide into the following steps:</p>
<ol>
<li>Compute $x$ and $y$ derivatives ($I_x, I_y$) of an image</li>
<li>Compute products of derivatives ($I_x^2, I_y^2, I_{xy}$) at each pixel</li>
<li>Compute matrix $M$ at each pixel, where
$$
M = \sum_{x,y} w(x,y)
    \begin{bmatrix}
        I_{x}^2 & I_{x}I_{y} \\
        I_{x}I_{y} & I_{y}^2
    \end{bmatrix}
$$
</li>
<li>Compute corner response $R&#x3D;Det(M)-k(Trace(M)^2)$ at each pixel</li>
<li>Output corner response map $R(x,y)$</li>
</ol>
<p>Step 1 is already done for you in the function <strong><code>harris_corners</code></strong> in <code>panorama.py</code>. Complete the function implementation and run the code below.</p>
<p><em>-Hint: You may use the function <code>scipy.ndimage.filters.convolve</code>, which is already imported in <code>panoramy.py</code></em></p>
<p><strong>Harris角点算法实现：</strong></p>
<ol>
<li>计算图像$I(x,y)$在$X$和$Y$两个方向的梯度</li>
<li>计算图像两个方向梯度的乘积</li>
<li>使用窗口函数对每个像素进行遍历，计算生成$M$矩阵：
$$
M = \sum_{x,y} w(x,y)
    \begin{bmatrix}
        I_{x}^2 & I_{x}I_{y} \\
        I_{x}I_{y} & I_{y}^2
    \end{bmatrix}
$$

实际计算时，可以计算矩阵$M$的四个部分，分别用窗口函数$w$对$I_x^2, I_y^2, I_{xy}$进行卷积，得到：
$$
M = \begin{bmatrix}
        A & C\\
        C & B
    \end{bmatrix}
$$
</li>
<li>计算每个像素的Harris响应值$R$，$R&#x3D;Det(M)-k(Trace(M)^2)$ ，此时Det(M)就等于$A\cdot B-C\cdot C$</li>
<li>输出焦点响应map $R(x,y)$</li>
</ol>
<blockquote>
<p><strong>博客推荐</strong> </p>
<p>关于Harris角点检测，这里有篇博客总结的很好，推荐。</p>
<p><strong><a target="_blank" rel="noopener" href="https://www.cnblogs.com/ronny/p/4009425.html">Harris角点</a></strong></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> panorama <span class="keyword">import</span> harris_corners</span><br><span class="line"></span><br><span class="line">img = imread(<span class="string">&#x27;sudoku.png&#x27;</span>, as_grey=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute Harris corner response</span></span><br><span class="line">response = harris_corners(img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display corner response</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.imshow(response)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Harris Corner Response&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.imshow(imread(<span class="string">&#x27;solution_harris.png&#x27;</span>, as_grey=<span class="literal">True</span>))</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Harris Corner Solution&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511005/blog/mzdcjzwwa5t8pdt2snag.png" alt="png"></p>
<p>Once you implement the Harris detector correctly, you will be able to see small bright blobs around the corners of the sudoku grids and letters in the output corner response image. The function <code>corner_peaks</code> from <code>skimage.feature</code> performs non-maximum suppression to take local maxima of the response map and localize keypoints.</p>
<p><strong>对响应输出进行非极大抑制。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Perform non-maximum suppression in response map</span></span><br><span class="line"><span class="comment"># and output corner coordiantes</span></span><br><span class="line">corners = corner_peaks(response, threshold_rel=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display detected corners</span></span><br><span class="line">plt.imshow(img)</span><br><span class="line">plt.scatter(corners[:,<span class="number">1</span>], corners[:,<span class="number">0</span>], marker=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Detected Corners&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511007/blog/s5k4bvnsxywgxrtbjjue.png" alt="png"></p>
<h2 id="Part-2-Describing-and-Matching-Keypoints-20-points"><a href="#Part-2-Describing-and-Matching-Keypoints-20-points" class="headerlink" title="Part 2 Describing and Matching Keypoints (20 points)"></a>Part 2 Describing and Matching Keypoints (20 points)</h2><p>We are now able to localize keypoints in two images by running the Harris corner detector independently on them. Next question is, how do we determine which pair of keypoints come from corresponding locations in those two images? In order to <em>match</em> the detected keypoints, we must come up with a way to <em>describe</em> the keypoints based on their local appearance. Generally, each region around detected keypoint locations is converted into  a fixed-size vectors called <em>descriptors</em>.</p>
<h3 id="Part-2-1-Creating-Descriptors-10-points"><a href="#Part-2-1-Creating-Descriptors-10-points" class="headerlink" title="Part 2.1 Creating Descriptors (10 points)"></a>Part 2.1 Creating Descriptors (10 points)</h3><p>In this section, you are going to implement a <strong><code>simple_descriptor</code></strong>; each keypoint is described by normalized intensity in a small patch around it.</p>
<p>为了进行两幅图像中的关键点的点与点之间的匹配，需要对关键点进行描述。</p>
<p>此时，提出描述符对关键点的局部特征进行描述。</p>
<p>一般来说，描述符就是将检测到的关键点的附近区域转换成固定大小的向量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> panorama <span class="keyword">import</span> harris_corners</span><br><span class="line"></span><br><span class="line">img1 = imread(<span class="string">&#x27;uttower1.jpg&#x27;</span>, as_grey=<span class="literal">True</span>)</span><br><span class="line">img2 = imread(<span class="string">&#x27;uttower2.jpg&#x27;</span>, as_grey=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Detect keypoints in two images</span></span><br><span class="line">keypoints1 = corner_peaks(harris_corners(img1, window_size=<span class="number">3</span>),</span><br><span class="line">                          threshold_rel=<span class="number">0.05</span>,</span><br><span class="line">                          exclude_border=<span class="number">8</span>)</span><br><span class="line">keypoints2 = corner_peaks(harris_corners(img2, window_size=<span class="number">3</span>),</span><br><span class="line">                          threshold_rel=<span class="number">0.05</span>,</span><br><span class="line">                          exclude_border=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display detected keypoints</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.imshow(img1)</span><br><span class="line">plt.scatter(keypoints1[:,<span class="number">1</span>], keypoints1[:,<span class="number">0</span>], marker=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Detected Keypoints for Image 1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.imshow(img2)</span><br><span class="line">plt.scatter(keypoints2[:,<span class="number">1</span>], keypoints2[:,<span class="number">0</span>], marker=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Detected Keypoints for Image 2&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511007/blog/qqtkqyphsb72aqtdpvq8.png" alt="png"></p>
<h3 id="Part-2-2-Matching-Descriptors-10-points"><a href="#Part-2-2-Matching-Descriptors-10-points" class="headerlink" title="Part 2.2 Matching Descriptors (10 points)"></a>Part 2.2 Matching Descriptors (10 points)</h3><p>Then, implement <strong><code>match_descriptors</code></strong> function to find good matches in two sets of descriptors. First, calculate Euclidean distance between all pairs of descriptors from image 1 and image 2. Then use this to determine if there is a good match: if the distance to the closest vector is significantly (by a factor which is given) smaller than the distance to the second-closest, we call it a match. The output of the function is an array where each row holds the indices of one pair of matching descriptors.</p>
<ul>
<li>使用标准化的密度来作为描述子</li>
<li>使用欧几里得距离来对描述子进行匹配,当最短距离与第二短距离的比值小于阈值，则判定为匹配</li>
</ul>
<blockquote>
<p>这份教程有帮助：<a target="_blank" rel="noopener" href="https://python3-cookbook.readthedocs.io/zh_CN/latest/c01/p04_find_largest_or_smallest_n_items.html">查找最大或最小的 N 个元素</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> panorama <span class="keyword">import</span> simple_descriptor, match_descriptors, describe_keypoints</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> plot_matches</span><br><span class="line"></span><br><span class="line">patch_size = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Extract features from the corners</span></span><br><span class="line">desc1 = describe_keypoints(img1, keypoints1,</span><br><span class="line">                           desc_func=simple_descriptor,</span><br><span class="line">                           patch_size=patch_size)</span><br><span class="line">desc2 = describe_keypoints(img2, keypoints2,</span><br><span class="line">                           desc_func=simple_descriptor,</span><br><span class="line">                           patch_size=patch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Match descriptors in image1 to those in image2</span></span><br><span class="line">matches = match_descriptors(desc1, desc2, <span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot matches</span></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">1</span>, figsize=(<span class="number">15</span>, <span class="number">12</span>))</span><br><span class="line">ax.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plot_matches(ax, img1, img2, keypoints1, keypoints2, matches)</span><br><span class="line">plt.show()</span><br><span class="line">plt.imshow(imread(<span class="string">&#x27;solution_simple_descriptor.png&#x27;</span>))</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Matched Simple Descriptor Solution&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511008/blog/llezbmkgrhos3ctjfonp.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511009/blog/gzfo0pxnwoc0nmkx9ehc.png" alt="png"></p>
<h2 id="Part-3-Transformation-Estimation-20-points"><a href="#Part-3-Transformation-Estimation-20-points" class="headerlink" title="Part 3 Transformation Estimation (20 points)"></a>Part 3 Transformation Estimation (20 points)</h2><p>We now have a list of matched keypoints across the two images. We will use this to find a transformation matrix that maps points in the second image to the corresponding coordinates in the first image. In other words, if the point $p_1 &#x3D; [y_1,x_1]$ in image 1 matches with $p_2&#x3D;[y_2, x_2]$ in image 2, we need to find an affine transformation matrix $H$ such that</p>
<p>$$<br>\tilde{p_2}H &#x3D; \tilde{p_1},<br>$$</p>
<p>where $\tilde{p_1}$ and $\tilde{p_2}$ are homogenous coordinates of $p_1$ and $p_2$.</p>
<p>Note that it may be impossible to find the transformation $H$ that maps every point in image 2 exactly to the corresponding point in image 1. However, we can estimate the transformation matrix with least squares. Given $N$ matched keypoint pairs, let $X_1$ and $X_2$ be $N \times 3$ matrices whose rows are homogenous coordinates of corresponding keypoints in image 1 and image 2 respectively. Then, we can estimate $H$ by solving the least squares problem,</p>
<p>$$<br>X_2 H &#x3D; X_1<br>$$</p>
<p>Implement <strong><code>fit_affine_matrix</code></strong> in <code>panorama.py</code></p>
<p><em>-Hint: read the <a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html">documentation</a> about np.linalg.lstsq</em></p>
<p>第三步就是要计算图2到图1的仿射变换矩阵。</p>
<p>由于匹配点对众多，这里采用最小二乘法估计变换矩阵。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> panorama <span class="keyword">import</span> fit_affine_matrix</span><br><span class="line"></span><br><span class="line"><span class="comment"># Sanity check for fit_affine_matrix</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Test inputs</span></span><br><span class="line">a = np.array([[<span class="number">0.5</span>, <span class="number">0.1</span>], [<span class="number">0.4</span>, <span class="number">0.2</span>], [<span class="number">0.8</span>, <span class="number">0.2</span>]])</span><br><span class="line">b = np.array([[<span class="number">0.3</span>, -<span class="number">0.2</span>], [-<span class="number">0.4</span>, -<span class="number">0.9</span>], [<span class="number">0.1</span>, <span class="number">0.1</span>]])</span><br><span class="line"></span><br><span class="line">H = fit_affine_matrix(b, a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Target output</span></span><br><span class="line">sol = np.array(</span><br><span class="line">    [[<span class="number">1.25</span>, <span class="number">2.5</span>, <span class="number">0.0</span>],</span><br><span class="line">     [-<span class="number">5.75</span>, -<span class="number">4.5</span>, <span class="number">0.0</span>],</span><br><span class="line">     [<span class="number">0.25</span>, -<span class="number">1.0</span>, <span class="number">1.0</span>]]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">error = np.<span class="built_in">sum</span>((H - sol) ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> error &lt; <span class="number">1e-20</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Implementation correct!&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;There is something wrong.&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Implementation correct!
</code></pre>
<p>After checking that your <code>fit_affine_matrix function</code> is running correctly, run the following code to apply it to images.<br>Images will be warped and image 2 will be mapped to image 1. Then, the two images are merged to get a panorama. Your panorama may not look good at this point, but we will later use other techniques to get a better result.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> get_output_space, warp_image</span><br><span class="line"></span><br><span class="line"><span class="comment"># Extract matched keypoints</span></span><br><span class="line">p1 = keypoints1[matches[:,<span class="number">0</span>]]</span><br><span class="line">p2 = keypoints2[matches[:,<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find affine transformation matrix H that maps p2 to p1</span></span><br><span class="line">H = fit_affine_matrix(p1, p2)</span><br><span class="line"></span><br><span class="line">output_shape, offset = get_output_space(img1, [img2], [H])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Output shape:&quot;</span>, output_shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Offset:&quot;</span>, offset)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Warp images into output sapce</span></span><br><span class="line">img1_warped = warp_image(img1, np.eye(<span class="number">3</span>), output_shape, offset)</span><br><span class="line">img1_mask = (img1_warped != -<span class="number">1</span>) <span class="comment"># Mask == 1 inside the image</span></span><br><span class="line">img1_warped[~img1_mask] = <span class="number">0</span>     <span class="comment"># Return background values to 0</span></span><br><span class="line"></span><br><span class="line">img2_warped = warp_image(img2, H, output_shape, offset)</span><br><span class="line">img2_mask = (img2_warped != -<span class="number">1</span>) <span class="comment"># Mask == 1 inside the image</span></span><br><span class="line">img2_warped[~img2_mask] = <span class="number">0</span>     <span class="comment"># Return background values to 0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot warped images</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.imshow(img1_warped)</span><br><span class="line">plt.title(<span class="string">&#x27;Image 1 warped&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.imshow(img2_warped)</span><br><span class="line">plt.title(<span class="string">&#x27;Image 2 warped&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>Output shape: [496 615]
Offset: [-39.37184617   0.        ]
</code></pre>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511009/blog/xxarzwoja3cxmiijiqi0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">merged = img1_warped + img2_warped</span><br><span class="line"></span><br><span class="line"><span class="comment"># Track the overlap by adding the masks together</span></span><br><span class="line">overlap = (img1_mask * <span class="number">1.0</span> +  <span class="comment"># Multiply by 1.0 for bool -&gt; float conversion</span></span><br><span class="line">           img2_mask)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize through division by `overlap` - but ensure the minimum is 1</span></span><br><span class="line">normalized = merged / np.maximum(overlap, <span class="number">1</span>)</span><br><span class="line">plt.imshow(normalized)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511010/blog/rk9qthgo7rhtngfd9zbu.png" alt="png"></p>
<p>这啥玩意啊，脑袋巨大。</p>
<h2 id="Part-4-RANSAC-20-points"><a href="#Part-4-RANSAC-20-points" class="headerlink" title="Part 4 RANSAC (20 points)"></a>Part 4 RANSAC (20 points)</h2><p>Rather than directly feeding all our keypoint matches into <code>fit_affine_matrix</code> function, we can instead use RANSAC (“RANdom SAmple Consensus”) to select only “inliers” to use to compute the transformation matrix.</p>
<p>The steps of RANSAC are:<br>    1. Select random set of matches<br>    2. Compute affine transformation matrix<br>    3. Find inliers using the given threshold<br>    4. Repeat and keep the largest set of inliers<br>    5. Re-compute least-squares estimate on all of the inliers</p>
<p>Implement <strong><code>ransac</code></strong> in <code>panorama.py</code>, run through the following code to get a panorama. You can see the difference from the result we get without RANSAC.</p>
<p>告别直接使用所有匹配对进行仿射变换矩阵估计的方式，</p>
<p>我们迎来了RANSAC随机抽样一致的方式来对inliers(非异常点即正常点)进行仿射变换的估计。</p>
<p>RANSAC的步骤为：</p>
<ol>
<li>随机选取一组匹配点</li>
<li>计算仿射变换矩阵</li>
<li>根据给定的阈值计算在正常范围内的匹配对的数目</li>
<li>不断重复，保留最大正常匹配对的数目</li>
<li>对保留的最大整整匹配对进行最小二乘法的估计，得到图2到图1的仿射变换矩阵。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> panorama <span class="keyword">import</span> ransac</span><br><span class="line">H, robust_matches = ransac(keypoints1, keypoints2, matches, threshold=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Visualize robust matches</span></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">1</span>, figsize=(<span class="number">15</span>, <span class="number">12</span>))</span><br><span class="line">plot_matches(ax, img1, img2, keypoints1, keypoints2, robust_matches)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.imshow(imread(<span class="string">&#x27;solution_ransac.png&#x27;</span>))</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;RANSAC Solution&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511010/blog/e0oacasoqtakwkpue78f.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511011/blog/ffsybwtoobpk3g5smj2b.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">output_shape, offset = get_output_space(img1, [img2], [H])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Warp images into output sapce</span></span><br><span class="line">img1_warped = warp_image(img1, np.eye(<span class="number">3</span>), output_shape, offset)</span><br><span class="line">img1_mask = (img1_warped != -<span class="number">1</span>) <span class="comment"># Mask == 1 inside the image</span></span><br><span class="line">img1_warped[~img1_mask] = <span class="number">0</span>     <span class="comment"># Return background values to 0</span></span><br><span class="line"></span><br><span class="line">img2_warped = warp_image(img2, H, output_shape, offset)</span><br><span class="line">img2_mask = (img2_warped != -<span class="number">1</span>) <span class="comment"># Mask == 1 inside the image</span></span><br><span class="line">img2_warped[~img2_mask] = <span class="number">0</span>     <span class="comment"># Return background values to 0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot warped images</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.imshow(img1_warped)</span><br><span class="line">plt.title(<span class="string">&#x27;Image 1 warped&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.imshow(img2_warped)</span><br><span class="line">plt.title(<span class="string">&#x27;Image 2 warped&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511012/blog/n0oeo039lahckbe8d4kr.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">merged = img1_warped + img2_warped</span><br><span class="line"></span><br><span class="line"><span class="comment"># Track the overlap by adding the masks together</span></span><br><span class="line">overlap = (img1_mask * <span class="number">1.0</span> +  <span class="comment"># Multiply by 1.0 for bool -&gt; float conversion</span></span><br><span class="line">           img2_mask)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize through division by `overlap` - but ensure the minimum is 1</span></span><br><span class="line">normalized = merged / np.maximum(overlap, <span class="number">1</span>)</span><br><span class="line">plt.imshow(normalized)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.imshow(imread(<span class="string">&#x27;solution_ransac_panorama.png&#x27;</span>))</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;RANSAC Panorama Solution&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511012/blog/jwara3fcmqhqieuobyjt.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511013/blog/y5a4rh2ux3o7uhqppzsf.png" alt="png"></p>
<p>哇靠，真的能拼接出来了。</p>
<p>我偷看了一眼 <a target="_blank" rel="noopener" href="https://github.com/mikucy/CS131/blob/master/hw3_release/panorama.py">mikucy的作业</a>，感谢！</p>
<p>上学期没做出来是因为我在进行处理随机抽样一致的时候，只进行了一定数目迭代，并在迭代过程中保留了效果最好的变换矩阵，但这个矩阵仅仅是用随机的片段估计出来的；</p>
<p>实际上迭代过程中的参数估计只是为了得到最大数目的局内点inliers的，最终的参数估计即仿射变换矩阵还是要根据迭代后保留的inliers进行最小二乘法估计出来。</p>
<p>也就是说迭代过程中的最优H，并不是最终的H。</p>
<h2 id="Part-5-Histogram-of-Oriented-Gradients-HOG-20-points"><a href="#Part-5-Histogram-of-Oriented-Gradients-HOG-20-points" class="headerlink" title="Part 5 Histogram of Oriented Gradients (HOG) (20 points)"></a>Part 5 Histogram of Oriented Gradients (HOG) (20 points)</h2><p>In the above code, you are using the <code>simple_descriptor</code>, and in this section, you are going to implement a simplified version of HOG descriptor. <br><br>HOG stands for Histogram of	Oriented Gradients. In HOG descriptor, the distribution ( histograms ) of directions of gradients ( oriented gradients ) are used as features. Gradients ( x and y derivatives ) of an image are useful because the magnitude of gradients is large around edges and corners ( regions of abrupt intensity changes ) and we know that edges and corners pack in a lot more information about object shape than flat regions.<br><br>The steps of HOG are:<br>    1. compute the gradient image in x and y<br>        Use the sobel filter provided by skimage.filters<br>    2. compute gradient histograms<br>        Divide image into cells, and calculate histogram of gradient in each cell.<br>    3. normalize across block<br>        Normalize the histogram so that they<br>    4. flattening block into a feature vector</p>
<p>Implement <strong><code>hog_descriptor</code></strong> in <code>panorama.py</code>, and run through the following code to get a panorama image.</p>
<p>HOG特征提取步骤（简化版本）：</p>
<ol>
<li>计算图像中x和y方向上的梯度</li>
<li>计算梯度直方图<br>将图像分成多个单元，计算每个单元内的梯度分布，梯度分布n个方向中，统计单元内每个方向的梯度强度之和</li>
<li>归一化图像块的直方图</li>
<li>将块直方图转换成向量</li>
</ol>
<blockquote>
<p><strong>博客推荐</strong></p>
<p>关于HOG特征的算法流程，可以阅读此文</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/hujingshuang/article/details/47337707">【特征检测】HOG特征算法</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> panorama <span class="keyword">import</span> hog_descriptor</span><br><span class="line"></span><br><span class="line">img1 = imread(<span class="string">&#x27;uttower1.jpg&#x27;</span>, as_grey=<span class="literal">True</span>)</span><br><span class="line">img2 = imread(<span class="string">&#x27;uttower2.jpg&#x27;</span>, as_grey=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Detect keypoints in both images</span></span><br><span class="line">keypoints1 = corner_peaks(harris_corners(img1, window_size=<span class="number">3</span>),</span><br><span class="line">                          threshold_rel=<span class="number">0.05</span>,</span><br><span class="line">                          exclude_border=<span class="number">8</span>)</span><br><span class="line">keypoints2 = corner_peaks(harris_corners(img2, window_size=<span class="number">3</span>),</span><br><span class="line">                          threshold_rel=<span class="number">0.05</span>,</span><br><span class="line">                          exclude_border=<span class="number">8</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Extract features from the corners</span></span><br><span class="line">desc1 = describe_keypoints(img1, keypoints1,</span><br><span class="line">                           desc_func=hog_descriptor,</span><br><span class="line">                           patch_size=<span class="number">16</span>)</span><br><span class="line">desc2 = describe_keypoints(img2, keypoints2,</span><br><span class="line">                           desc_func=hog_descriptor,</span><br><span class="line">                           patch_size=<span class="number">16</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Match descriptors in image1 to those in image2</span></span><br><span class="line">matches = match_descriptors(desc1, desc2, <span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot matches</span></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">1</span>, figsize=(<span class="number">15</span>, <span class="number">12</span>))</span><br><span class="line">ax.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plot_matches(ax, img1, img2, keypoints1, keypoints2, matches)</span><br><span class="line">plt.show()</span><br><span class="line">plt.imshow(imread(<span class="string">&#x27;solution_hog.png&#x27;</span>))</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;HOG descriptor Solution&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511013/blog/qepn9o4wkx5zqyvveae8.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511014/blog/yyb7mpgvcbq08ug6zrxb.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> panorama <span class="keyword">import</span> ransac</span><br><span class="line">H, robust_matches = ransac(keypoints1, keypoints2, matches, threshold=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot matches</span></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>, <span class="number">1</span>, figsize=(<span class="number">15</span>, <span class="number">12</span>))</span><br><span class="line">plot_matches(ax, img1, img2, keypoints1, keypoints2, robust_matches)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.imshow(imread(<span class="string">&#x27;solution_hog_ransac.png&#x27;</span>))</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;HOG descriptor Solution&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511015/blog/bozuu1b3sslcidzaxwqz.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511015/blog/o8apwrewmgvielqollfe.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">output_shape, offset = get_output_space(img1, [img2], [H])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Warp images into output sapce</span></span><br><span class="line">img1_warped = warp_image(img1, np.eye(<span class="number">3</span>), output_shape, offset)</span><br><span class="line">img1_mask = (img1_warped != -<span class="number">1</span>) <span class="comment"># Mask == 1 inside the image</span></span><br><span class="line">img1_warped[~img1_mask] = <span class="number">0</span>     <span class="comment"># Return background values to 0</span></span><br><span class="line"></span><br><span class="line">img2_warped = warp_image(img2, H, output_shape, offset)</span><br><span class="line">img2_mask = (img2_warped != -<span class="number">1</span>) <span class="comment"># Mask == 1 inside the image</span></span><br><span class="line">img2_warped[~img2_mask] = <span class="number">0</span>     <span class="comment"># Return background values to 0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot warped images</span></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.imshow(img1_warped)</span><br><span class="line">plt.title(<span class="string">&#x27;Image 1 warped&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.imshow(img2_warped)</span><br><span class="line">plt.title(<span class="string">&#x27;Image 2 warped&#x27;</span>)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511016/blog/c8y65hm6tini3jal2x3o.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">merged = img1_warped + img2_warped</span><br><span class="line"></span><br><span class="line"><span class="comment"># merge之后重叠部分亮度上来了，需要通过归一化回复原来亮度</span></span><br><span class="line"><span class="comment"># Track the overlap by adding the masks together</span></span><br><span class="line">overlap = (img1_mask * <span class="number">1.0</span> +  <span class="comment"># Multiply by 1.0 for bool -&gt; float conversion</span></span><br><span class="line">           img2_mask)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize through division by `overlap` - but ensure the minimum is 1</span></span><br><span class="line">normalized = merged / np.maximum(overlap, <span class="number">1</span>)</span><br><span class="line">plt.imshow(normalized)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.imshow(imread(<span class="string">&#x27;solution_hog_panorama.png&#x27;</span>))</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;HOG Descriptor Panorama Solution&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511016/blog/dpouua5dmhntazssxlyk.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511017/blog/ulrryjjjyvsyrh1pvqc6.png" alt="png"></p>
<p>实现了<strong>HOG特征描述符</strong>之后，可以替代掉之前的<strong>归一化密度</strong>作为特征的匹配。，效果还不错。</p>
<h2 id="Extra-Credit-Better-Image-Merging"><a href="#Extra-Credit-Better-Image-Merging" class="headerlink" title="Extra Credit: Better Image Merging"></a>Extra Credit: Better Image Merging</h2><p>You will notice the blurry region and unpleasant lines in the middle of the final panoramic image. In the cell below, come up with a better merging scheme to make the panorama look more natural. Be creative!</p>
<p><strong>怎么消除拼接处的两条拼接痕迹呢？</strong></p>
<blockquote>
<p>第一，翻博客  <a target="_blank" rel="noopener" href="https://www.cnblogs.com/skyfsm/p/7411961.html?tdsourcetag=s_pctim_aiomsg">OpenCV探索之路（二十四）图像拼接和图像融合技术</a></p>
<p>第二，看论文 <a target="_blank" rel="noopener" href="http://matthewalunbrown.com/papers/ijcv2007.pdf">《Automatic Panoramic Image Stitching using Invariant Features》</a></p>
</blockquote>
<p><strong>加权融合</strong></p>
<p>博客上的处理思路是加权融合，在重叠部分由前一幅图像慢慢过渡到第二幅图像，即将图像的重叠区域的像素值按一定的权值相加合成新的图像。</p>
<p>我的理解就是两块重叠的区域，从左向右每个像素由图1和图2融合，最开始图1的权重最大，图2的权重最小，向右融合过程中图1权重逐渐减小，图2权重逐渐增大。</p>
<p>融合的公式可以简单理解成：</p>

$$
dst[i,j] = Img_1[i,j] * \alpha_{[i,j]}+ Img_2[i,j] * (1-\alpha_{[i,j]})
$$


<p>而权重$\alpha$的则与像素点在重叠区域的位置相关，可以定义成：</p>

$$
\alpha_{[row,col]} = (col - Left_{region}) / (Width_{region})  
$$



<p><strong>增益补偿和多频带混合</strong><br>论文《Automatic Panoramic Image Stitching using Invariant Features》正是一篇不错的文章啊，我快速过了一遍。</p>
<p>论文针对拼接步骤，提出了三点：</p>
<ol>
<li>自动拼接校直 Automatic Panorama Straightening</li>
<li>增益补偿 Gain Compensation</li>
<li>多频带混合 Multi-Band Blending</li>
</ol>
<p>校直是用BA做的相机参数的估计，用来解决拼接过程中的图像的旋转</p>
<p>增益补偿是用过使用最小二乘法计算每个拼接块的增益，用来均衡整幅图像中各个拼接块的亮度不均问题</p>
<p>多频带混合还没有看懂</p>
<p>实现的话目前没有动力实现了。加一个TODO，后面用空再做吧，而且BA实现这种东西，我的C++还半生不熟，Python下更是有心无力了。</p>
<p>TODO：实现《Automatic Panoramic Image Stitching using Invariant Features》</p>
<p>不过GitHub上倒是有个开源的拼接库<a target="_blank" rel="noopener" href="https://github.com/ppwwyyxx/OpenPano">OpenPano</a>，感兴趣可以看一下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Modify the code below</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### YOUR CODE HERE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># #  拼接方法一：题目原有方法，两幅图叠加后在对重叠区域和非重叠区域做亮度调整。</span></span><br><span class="line">merged = img1_warped + img2_warped</span><br><span class="line">overlap = (img1_mask * <span class="number">1.0</span> + img2_mask)</span><br><span class="line">output = merged / np.maximum(overlap, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.imshow(output)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Way Origin&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拼接方法二：加权融合</span></span><br><span class="line"><span class="comment"># 先把两幅图叠加在一起</span></span><br><span class="line">merged = img1_warped + img2_warped</span><br><span class="line"><span class="comment"># overlap = (img1_mask * 1.0 + img2_mask)</span></span><br><span class="line"><span class="comment"># output = merged / np.maximum(overlap, 1)</span></span><br><span class="line"><span class="comment"># 1. 找到重叠区域在warped图像中的左边界和右边界，可以根据已知的mask图像进行判断</span></span><br><span class="line"><span class="comment"># 1.1 重叠区域左边界就是img2_mask中第一个不全为零的列</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(img2_warped.shape[<span class="number">1</span>]):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> np.<span class="built_in">all</span>(img2_mask[:, col] == <span class="literal">False</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">regionLeft = col</span><br><span class="line"><span class="comment"># 1.2 重叠区域右边界就是img1_mask中有值区域的右边，其实就是img1的宽所在的列</span></span><br><span class="line">regionRight = img1.shape[<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 1.3 区域宽度</span></span><br><span class="line">regionWidth = regionRight - regionLeft + <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 遍历区域内像素点进行融合</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(regionLeft, regionRight+<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(img2_warped.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="comment"># 2.1 计算α</span></span><br><span class="line">        alpha = (col - regionLeft) / (regionWidth)</span><br><span class="line">        alpha = <span class="number">1</span> - alpha</span><br><span class="line">        <span class="comment"># 2.2 处理区域内的重叠点</span></span><br><span class="line">        <span class="keyword">if</span> img1_mask[row,col] <span class="keyword">and</span> img2_mask[row,col]:</span><br><span class="line">            merged[row,col] = alpha * img1_warped[row,col] + (<span class="number">1</span> - alpha) * img2_warped[row,col]</span><br><span class="line">        </span><br><span class="line">output = merged</span><br><span class="line"></span><br><span class="line">plt.imshow(output)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Way 1:  weighted fusion&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">### END YOUR CODE</span></span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511018/blog/eskritbf1zow10xtrmdw.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511019/blog/f5kkmnar1r4oiedxrvf3.png" alt="png"></p>
<h2 id="Extra-Credit-Stitching-Multiple-Images"><a href="#Extra-Credit-Stitching-Multiple-Images" class="headerlink" title="Extra Credit: Stitching Multiple Images"></a>Extra Credit: Stitching Multiple Images</h2><p>Work in the cell below to complete the code to stitch an ordered chain of images.</p>
<p>Given a sequence of $m$ images ($I_1, I_2,…,I_m$), take every neighboring pair of images and compute the transformation matrix which converts points from the coordinate frame of $I_{i+1}$ to the frame of $I_{i}$. Then, select a reference image $I_{ref}$, which is in the middle of the chain. We want our final panorama image to be in the coordinate frame of $I_{ref}$. So, for each $I_i$ that is not the reference image, we need a transformation matrix that will convert points in frame $i$ to frame $ref$.</p>
<p><em>-Hint:</em></p>
<ul>
<li>If you are confused, you may want to review the Linear Algebra slides on how to combine the effects of multiple transformation matrices.</li>
<li>The inverse of transformation matrix has the reverse effect. Please use <a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.inv.html"><code>numpy.linalg.inv</code></a> function whenever you want to compute matrix inverse.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line">img1 = imread(<span class="string">&#x27;yosemite1.jpg&#x27;</span>, as_grey=<span class="literal">True</span>)</span><br><span class="line">img2 = imread(<span class="string">&#x27;yosemite2.jpg&#x27;</span>, as_grey=<span class="literal">True</span>)</span><br><span class="line">img3 = imread(<span class="string">&#x27;yosemite3.jpg&#x27;</span>, as_grey=<span class="literal">True</span>)</span><br><span class="line">img4 = imread(<span class="string">&#x27;yosemite4.jpg&#x27;</span>, as_grey=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Detect keypoints in each image</span></span><br><span class="line">keypoints1 = corner_peaks(harris_corners(img1, window_size=<span class="number">3</span>),</span><br><span class="line">                          threshold_rel=<span class="number">0.05</span>,</span><br><span class="line">                          exclude_border=<span class="number">8</span>)</span><br><span class="line">keypoints2 = corner_peaks(harris_corners(img2, window_size=<span class="number">3</span>),</span><br><span class="line">                          threshold_rel=<span class="number">0.05</span>,</span><br><span class="line">                          exclude_border=<span class="number">8</span>)</span><br><span class="line">keypoints3 = corner_peaks(harris_corners(img3, window_size=<span class="number">3</span>),</span><br><span class="line">                          threshold_rel=<span class="number">0.05</span>,</span><br><span class="line">                          exclude_border=<span class="number">8</span>)</span><br><span class="line">keypoints4 = corner_peaks(harris_corners(img4, window_size=<span class="number">3</span>),</span><br><span class="line">                          threshold_rel=<span class="number">0.05</span>,</span><br><span class="line">                          exclude_border=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe keypoints</span></span><br><span class="line">desc1 = describe_keypoints(img1, keypoints1,</span><br><span class="line">                           desc_func=simple_descriptor,</span><br><span class="line">                           patch_size=patch_size)</span><br><span class="line">desc2 = describe_keypoints(img2, keypoints2,</span><br><span class="line">                           desc_func=simple_descriptor,</span><br><span class="line">                           patch_size=patch_size)</span><br><span class="line">desc3 = describe_keypoints(img3, keypoints3,</span><br><span class="line">                           desc_func=simple_descriptor,</span><br><span class="line">                           patch_size=patch_size)</span><br><span class="line">desc4 = describe_keypoints(img4, keypoints4,</span><br><span class="line">                           desc_func=simple_descriptor,</span><br><span class="line">                           patch_size=patch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Match keypoints in neighboring images</span></span><br><span class="line">matches12 = match_descriptors(desc1, desc2, <span class="number">0.7</span>)</span><br><span class="line">matches23 = match_descriptors(desc2, desc3, <span class="number">0.7</span>)</span><br><span class="line">matches34 = match_descriptors(desc3, desc4, <span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">### YOUR CODE HERE</span></span><br><span class="line"><span class="comment"># RANSAC 估计 仿射变换矩阵</span></span><br><span class="line">H12, robust_matches12 = ransac(keypoints1, keypoints2, matches12, threshold=<span class="number">1</span>)</span><br><span class="line">H23, robust_matches23 = ransac(keypoints2, keypoints3, matches23, threshold=<span class="number">1</span>)</span><br><span class="line">H34, robust_matches34 = ransac(keypoints3, keypoints4, matches34, threshold=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成outspace大背景</span></span><br><span class="line"><span class="comment"># 注意utils.py中的get_output_space用法，参数2:imgs与参数3：transforms要对应</span></span><br><span class="line"><span class="comment"># 注意选取referImg 参考图像，这里选择图2</span></span><br><span class="line">output_shape, offset = get_output_space(img2, [img1, img3, img4], [np.linalg.inv(H12), H23, np.dot(H23,H34)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将图像放入大背景中</span></span><br><span class="line"><span class="comment"># Warp images into output sapce</span></span><br><span class="line">img1_warped = warp_image(img1, np.linalg.inv(H12), output_shape, offset)</span><br><span class="line">img1_mask = (img1_warped != -<span class="number">1</span>) <span class="comment"># Mask == 1 inside the image</span></span><br><span class="line">img1_warped[~img1_mask] = <span class="number">0</span>     <span class="comment"># Return background values to 0</span></span><br><span class="line"></span><br><span class="line">img2_warped = warp_image(img2, np.eye(<span class="number">3</span>), output_shape, offset)</span><br><span class="line">img2_mask = (img2_warped != -<span class="number">1</span>) <span class="comment"># Mask == 1 inside the image</span></span><br><span class="line">img2_warped[~img2_mask] = <span class="number">0</span>     <span class="comment"># Return background values to 0</span></span><br><span class="line"></span><br><span class="line">img3_warped = warp_image(img3, H23, output_shape, offset)</span><br><span class="line">img3_mask = (img3_warped != -<span class="number">1</span>) <span class="comment"># Mask == 1 inside the image</span></span><br><span class="line">img3_warped[~img3_mask] = <span class="number">0</span>     <span class="comment"># Return background values to 0</span></span><br><span class="line"></span><br><span class="line">img4_warped = warp_image(img4,  np.dot(H23,H34), output_shape, offset)</span><br><span class="line">img4_mask = (img4_warped != -<span class="number">1</span>) <span class="comment"># Mask == 1 inside the image</span></span><br><span class="line">img4_warped[~img4_mask] = <span class="number">0</span>     <span class="comment"># Return background values to 0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.imshow(img1_warped)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Image 1 warped&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.imshow(img2_warped)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Image 2 warped&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.imshow(img3_warped)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Image 3 warped&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.imshow(img4_warped)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Image 4 warped&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">### END YOUR CODE</span></span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511019/blog/bbeyop2feswslpohzfdi.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511020/blog/ht3zlfqyufjax4pfhpjf.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511020/blog/xmt9i3mcxb306simvph0.png" alt="png"></p>
<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511021/blog/pkksviadsttuvdfxjhdh.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  进行拼接，拼接方式一</span></span><br><span class="line">merged = img1_warped + img2_warped + img3_warped + img4_warped</span><br><span class="line"></span><br><span class="line"><span class="comment"># Track the overlap by adding the masks together</span></span><br><span class="line">overlap = (img2_mask * <span class="number">1.0</span> +  <span class="comment"># Multiply by 1.0 for bool -&gt; float conversion</span></span><br><span class="line">           img1_mask + img3_mask + img4_mask)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize through division by `overlap` - but ensure the minimum is 1</span></span><br><span class="line">normalized = merged / np.maximum(overlap, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.imshow(normalized)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img data-src="https://res.cloudinary.com/dgchmgebr/image/upload/v1678511021/blog/nv3ut1javufs5kqciefi.png" alt="png"></p>
<p>多幅图的拼接就可以看出来简单方式的问题了：</p>
<ol>
<li>拼接痕迹的存在，可以使用加权平均，</li>
<li>各个拼接块亮度不均匀，需要做增益补偿，</li>
<li>存在未知的图像的旋转，可能是由于拍摄时相机发生了位姿的变动，需要做优化处理（校直），</li>
<li>重叠部分的拼接并不能直接实现所有像素的对应叠加，可以看出来存在模糊的情况，可以使用多频带混合的方式去做处理。</li>
</ol>
<p>这些在《Automatic Panoramic Image Stitching using Invariant Features》都提到了。感兴趣可以继续研究，我先做下一份作业了。</p>
<h1 id="代码档案"><a href="#代码档案" class="headerlink" title="代码档案"></a>代码档案</h1><p><a target="_blank" rel="noopener" href="https://github.com/StanfordVL/CS131_release/tree/master/hw3_release">官方Repo作业材料</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/veraposeidon/CS131_Assignments/tree/master/hw3_release">个人Repo作业存档</a></p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>xiaohai
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://shenxiaohai.me/cs131-homework3/" title="CS131,Homewrok3,Panorama-ImageStiching">https://shenxiaohai.me/cs131-homework3/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" rel="tag"><i class="fa fa-tag"></i> 计算机视觉</a>
              <a href="/tags/CS131/" rel="tag"><i class="fa fa-tag"></i> CS131</a>
              <a href="/tags/%E5%9B%BE%E5%83%8F%E6%8B%BC%E6%8E%A5/" rel="tag"><i class="fa fa-tag"></i> 图像拼接</a>
              <a href="/tags/%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B/" rel="tag"><i class="fa fa-tag"></i> 角点检测</a>
              <a href="/tags/RANSAC/" rel="tag"><i class="fa fa-tag"></i> RANSAC</a>
              <a href="/tags/HOG%E6%8F%8F%E8%BF%B0%E5%AD%90/" rel="tag"><i class="fa fa-tag"></i> HOG描述子</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/ros-opencv/" rel="prev" title="在ROS中使用OpenCV进行视觉编程（Python版本）">
                  <i class="fa fa-chevron-left"></i> 在ROS中使用OpenCV进行视觉编程（Python版本）
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/cs131-homework4/" rel="next" title="CS131,Homewrok4,Resizing-SeamCarving">
                  CS131,Homewrok4,Resizing-SeamCarving <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments"><div id="twikoo-comments"></div></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2018 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-laptop"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xiaohai</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/veraposeidon" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.8/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://shenxiaohai.me/cs131-homework3/"}</script>
  <script src="/js/third-party/quicklink.js"></script>
<script class="next-config" data-name="twikoo" type="application/json">{"enable":true,"visitor":false,"envId":"https://twikoo-comment.shenxiaohai.me/","el":"#twikoo-comments"}</script>
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.twikoo.el)
    .then(() => NexT.utils.getScript(
      CONFIG.twikoo.jsUrl || 'https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js',
      { condition: window.twikoo }
    ))
    .then(() => {
      twikoo.init(CONFIG.twikoo);
    });
});
</script>
<style>
.post-block, .comments {
  overflow: visible;
}
.tk-owo-emotion {
  display: inline-block;
}
</style>

</body>
</html>
